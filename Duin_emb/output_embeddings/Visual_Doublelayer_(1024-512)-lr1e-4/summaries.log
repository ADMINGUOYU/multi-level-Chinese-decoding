2025-11-05 04:13:02,616: INFO: Complete the initialization of the training process with params ({'model': {'dataset': 'seeg_he2023xuanwu', 'device': device(type='cpu'), 'precision': torch.float32, 'n_subjects': 10, 'n_channels': 16, 'seq_len': 4000, 'seg_len': 100, 'n_labels': 61, 'subj': {'n_subjects': 10, 'd_input': 16, 'd_output': 16, 'use_bias': True, 'use_proj': False}, 'tokenizer': {'grad_scale': 1.0, 'd_neural': 16, 'seg_len': 100, 'n_filters': [128, 128, 16], 'kernel_sizes': [19, 3, 3], 'n_strides': [10, 1, 1], 'dilation_rates': [1, 1, 1], 'use_bn': [True, True, True], 'use_res': [False, False, False], 'pool_sizes': [1, 1, 1], 'd_model': 160, 'token_len': 40}, 'encoder': {'d_model': 160, 'emb_len': 40, 'n_blocks': 8, 'res_attn': False, 'n_heads': 8, 'd_head': 64, 'rot_theta': None, 'attn_dropout': 0.2, 'proj_dropout': 0.0, 'd_ff': 320, 'ff_dropout': [0.2, 0.0], 'norm_first': False}, 'vq': {'d_model': 160, 'codex_size': 2048, 'd_codex': 64, 'beta': 1.0, 'decay': 0.99, 'init_kmeans': True}, 'cls_loss_scale': 0.0, 'contra_loss_scale': 0.5, 'rgs_loss_scale': 0.0, 'vq_loss_scale': 0.0, 'align_loss_scale': 5.0, 'contra': {'d_model': 160, 'd_contra': 32, 'loss_mode': 'clip_orig'}, 'align': {'d_feature': 6400, 'd_output': 768, 'd_hidden': [1024, 512], 'dropout': 0.1}}, 'train': {'dataset': 'seeg_he2023xuanwu', 'base': '/mnt/afs/250010218/multi-level-Chinese-decoding/train/duin/../..', 'local_rank': 0, 'subjs': ['001'], 'precision': torch.float32, 'use_graph_mode': False, 'train_ratio': 0.8, 'buffer_size': 10000, 'n_samples': 5, 'i_save': 5, 'n_epochs': 300, 'warmup_epochs': 20, 'batch_size': 32, 'lr_factors': (1e-05, 0.0005), 'lr_i': 2.5e-05, 'subj_idxs': [0], 'pt_ckpt': './pretrains/duin/001/mae/model/checkpoint-399.pth'}}).
2025-11-05 04:13:02,626: Training started with dataset seeg_he2023xuanwu.
2025-11-05 04:13:02,667: cuda:0
2025-11-05 04:13:02,667: Training started with experiment train-task-all-speak-test-task-all-speak with 1 subjects.
2025-11-05 04:14:09,482: INFO: Data preparation for subject (001) complete, with train-set ((2425, 3000, 10)) & validation-set ((320, 3000, 10)) & test-set ((320, 3000, 10)).
2025-11-05 04:14:09,643: INFO: Data preparation complete, with train-set ((2425, 3000, 10)) & validation-set ((320, 3000, 10)) & test-set ((320, 3000, 10)).
2025-11-05 04:14:23,066: Finish train epoch 0 in 11.29 seconds.
2025-11-05 04:14:23,067: Loss(train): 6.51630 (total); 1.09776 (align); 2.05498 (contra)
2025-11-05 04:14:23,067: Loss(validation): 2.94004 (total); 0.38259 (align); 2.05421 (contra)
2025-11-05 04:14:23,067: Loss(test): 2.91055 (total); 0.37483 (align); 2.07276 (contra)
2025-11-05 04:14:23,086: ============================================================================================================================================
Layer (type:depth-idx)                                            Param #                   Param %                   Trainable
============================================================================================================================================
duin_align                                                        --                             --                   Partial
├─SubjectBlock: 1-1                                               --                             --                   True
│    └─SubjectLayer: 2-1                                          --                             --                   True
│    │    └─Linear: 3-1                                           160                         0.00%                   True
│    │    └─Linear: 3-2                                           16                          0.00%                   True
├─PatchTokenizer: 1-2                                             --                             --                   True
│    └─Sequential: 2-2                                            --                             --                   True
│    │    └─Sequential: 3-3                                       39,296                      0.41%                   True
│    │    └─Sequential: 3-4                                       49,536                      0.52%                   True
│    │    └─Sequential: 3-5                                       6,192                       0.06%                   True
├─TimeEmbedding: 1-3                                              (4,800)                     0.05%                   False
├─Sequential: 1-4                                                 --                             --                   Partial
│    └─LambdaLayer: 2-3                                           --                             --                   --
│    └─TransformerStack: 2-4                                      --                             --                   Partial
│    │    └─ModuleList: 3-6                                       3,465,224                  36.13%                   Partial
│    └─LambdaLayer: 2-5                                           --                             --                   --
├─LaBraMVectorQuantizer: 1-5                                      2,048                       0.02%                   Partial
│    └─Sequential: 2-6                                            --                             --                   True
│    │    └─Linear: 3-7                                           25,760                      0.27%                   True
│    │    └─Tanh: 3-8                                             --                             --                   --
│    │    └─Linear: 3-9                                           10,304                      0.11%                   True
│    └─EMAEmbedding: 2-7                                          (131,073)                   1.37%                   False
│    └─LayerNorm: 2-8                                             128                         0.00%                   True
│    └─Sequential: 2-9                                            --                             --                   True
│    │    └─Linear: 3-10                                          10,400                      0.11%                   True
├─ContrastiveBlock: 1-6                                           1                           0.00%                   Partial
│    └─Sequential: 2-10                                           --                             --                   True
│    │    └─Linear: 3-11                                          5,152                       0.05%                   True
│    │    └─Flatten: 3-12                                         --                             --                   --
│    └─Sequential: 2-11                                           --                             --                   True
│    │    └─Linear: 3-13                                          5,152                       0.05%                   True
│    │    └─Flatten: 3-14                                         --                             --                   --
├─AlignHead: 1-7                                                  --                             --                   True
│    └─Sequential: 2-12                                           --                             --                   True
│    │    └─Flatten: 3-15                                         --                             --                   --
│    │    └─Sequential: 3-16                                      4,916,224                  51.26%                   True
│    │    └─Sequential: 3-17                                      524,800                     5.47%                   True
│    │    └─Dropout: 3-18                                         --                             --                   --
│    │    └─Linear: 3-19                                          393,984                     4.11%                   True
============================================================================================================================================
Total params: 9,590,250
Trainable params: 9,452,320
Non-trainable params: 137,930
============================================================================================================================================
2025-11-05 04:14:23,212: Initial checkpoint saved at /mnt/afs/250010218/multi-level-Chinese-decoding/train/duin/../../summaries/2025-11-05/4/train/ckpt/epoch_000_loss_2.94004.pt
2025-11-05 04:14:32,991: Finish train epoch 1 in 9.78 seconds.
2025-11-05 04:14:32,992: Loss(train): 2.94748 (total); 0.39089 (align); 1.98610 (contra)
2025-11-05 04:14:32,992: Loss(validation): 2.50144 (total); 0.29515 (align); 2.05137 (contra)
2025-11-05 04:14:32,992: Loss(test): 2.47295 (total); 0.28859 (align); 2.06003 (contra)
2025-11-05 04:14:33,113: New best model saved (epoch 1) with val_loss=2.501438
2025-11-05 04:14:42,828: Finish train epoch 2 in 9.71 seconds.
2025-11-05 04:14:42,829: Loss(train): 2.71450 (total); 0.34584 (align); 1.97062 (contra)
2025-11-05 04:14:42,830: Loss(validation): 2.49821 (total); 0.29276 (align); 2.06886 (contra)
2025-11-05 04:14:42,830: Loss(test): 2.47723 (total); 0.28699 (align); 2.08461 (contra)
2025-11-05 04:14:42,942: New best model saved (epoch 2) with val_loss=2.498212
2025-11-05 04:14:52,657: Finish train epoch 3 in 9.71 seconds.
2025-11-05 04:14:52,658: Loss(train): 2.62292 (total); 0.32768 (align); 1.96901 (contra)
2025-11-05 04:14:52,658: Loss(validation): 2.48605 (total); 0.29258 (align); 2.04632 (contra)
2025-11-05 04:14:52,658: Loss(test): 2.46152 (total); 0.28644 (align); 2.05863 (contra)
2025-11-05 04:14:52,757: New best model saved (epoch 3) with val_loss=2.486047
2025-11-05 04:15:02,478: Finish train epoch 4 in 9.72 seconds.
2025-11-05 04:15:02,478: Loss(train): 2.56628 (total); 0.31642 (align); 1.96836 (contra)
2025-11-05 04:15:02,479: Loss(validation): 2.47040 (total); 0.29136 (align); 2.02717 (contra)
2025-11-05 04:15:02,479: Loss(test): 2.43627 (total); 0.28500 (align); 2.02250 (contra)
2025-11-05 04:15:02,578: New best model saved (epoch 4) with val_loss=2.470402
2025-11-05 04:15:12,286: Finish train epoch 5 in 9.71 seconds.
2025-11-05 04:15:12,286: Loss(train): 2.52795 (total); 0.30960 (align); 1.95989 (contra)
2025-11-05 04:15:12,287: Loss(validation): 2.46077 (total); 0.29108 (align); 2.01078 (contra)
2025-11-05 04:15:12,287: Loss(test): 2.43513 (total); 0.28519 (align); 2.01834 (contra)
2025-11-05 04:15:12,388: New best model saved (epoch 5) with val_loss=2.460775
2025-11-05 04:15:22,101: Finish train epoch 6 in 9.71 seconds.
2025-11-05 04:15:22,101: Loss(train): 2.49851 (total); 0.30438 (align); 1.95324 (contra)
2025-11-05 04:15:22,102: Loss(validation): 2.45823 (total); 0.29131 (align); 2.00334 (contra)
2025-11-05 04:15:22,102: Loss(test): 2.43138 (total); 0.28475 (align); 2.01526 (contra)
2025-11-05 04:15:22,201: New best model saved (epoch 6) with val_loss=2.458233
2025-11-05 04:15:31,920: Finish train epoch 7 in 9.72 seconds.
2025-11-05 04:15:31,921: Loss(train): 2.48078 (total); 0.30122 (align); 1.94933 (contra)
2025-11-05 04:15:31,921: Loss(validation): 2.44699 (total); 0.29025 (align); 1.99147 (contra)
2025-11-05 04:15:31,921: Loss(test): 2.42090 (total); 0.28462 (align); 1.99556 (contra)
2025-11-05 04:15:32,015: New best model saved (epoch 7) with val_loss=2.446994
2025-11-05 04:15:41,725: Finish train epoch 8 in 9.71 seconds.
2025-11-05 04:15:41,726: Loss(train): 2.46375 (total); 0.29818 (align); 1.94573 (contra)
2025-11-05 04:15:41,726: Loss(validation): 2.44853 (total); 0.29088 (align); 1.98821 (contra)
2025-11-05 04:15:41,726: Loss(test): 2.41739 (total); 0.28470 (align); 1.98781 (contra)
2025-11-05 04:15:51,496: Finish train epoch 9 in 9.77 seconds.
2025-11-05 04:15:51,497: Loss(train): 2.45337 (total); 0.29615 (align); 1.94524 (contra)
2025-11-05 04:15:51,498: Loss(validation): 2.44479 (total); 0.29028 (align); 1.98677 (contra)
2025-11-05 04:15:51,498: Loss(test): 2.41619 (total); 0.28472 (align); 1.98520 (contra)
2025-11-05 04:15:51,594: New best model saved (epoch 9) with val_loss=2.444790
2025-11-05 04:16:01,317: Finish train epoch 10 in 9.72 seconds.
2025-11-05 04:16:01,318: Loss(train): 2.44187 (total); 0.29376 (align); 1.94618 (contra)
2025-11-05 04:16:01,318: Loss(validation): 2.45326 (total); 0.29136 (align); 1.99293 (contra)
2025-11-05 04:16:01,318: Loss(test): 2.42006 (total); 0.28470 (align); 1.99313 (contra)
2025-11-05 04:16:10,993: Finish train epoch 11 in 9.67 seconds.
2025-11-05 04:16:10,994: Loss(train): 2.43438 (total); 0.29228 (align); 1.94596 (contra)
2025-11-05 04:16:10,994: Loss(validation): 2.44329 (total); 0.28978 (align); 1.98878 (contra)
2025-11-05 04:16:10,994: Loss(test): 2.41778 (total); 0.28417 (align); 1.99388 (contra)
2025-11-05 04:16:11,091: New best model saved (epoch 11) with val_loss=2.443293
2025-11-05 04:16:20,785: Finish train epoch 12 in 9.69 seconds.
2025-11-05 04:16:20,786: Loss(train): 2.42578 (total); 0.29036 (align); 1.94796 (contra)
2025-11-05 04:16:20,786: Loss(validation): 2.44307 (total); 0.29045 (align); 1.98161 (contra)
2025-11-05 04:16:20,786: Loss(test): 2.41455 (total); 0.28449 (align); 1.98415 (contra)
2025-11-05 04:16:20,882: New best model saved (epoch 12) with val_loss=2.443067
2025-11-05 04:16:30,605: Finish train epoch 13 in 9.72 seconds.
2025-11-05 04:16:30,605: Loss(train): 2.41495 (total); 0.28787 (align); 1.95124 (contra)
2025-11-05 04:16:30,606: Loss(validation): 2.45051 (total); 0.29025 (align); 1.99854 (contra)
2025-11-05 04:16:30,606: Loss(test): 2.42175 (total); 0.28380 (align); 2.00553 (contra)
2025-11-05 04:16:40,320: Finish train epoch 14 in 9.71 seconds.
2025-11-05 04:16:40,321: Loss(train): 2.41395 (total); 0.28733 (align); 1.95463 (contra)
2025-11-05 04:16:40,321: Loss(validation): 2.43032 (total); 0.28608 (align); 1.99988 (contra)
2025-11-05 04:16:40,321: Loss(test): 2.40655 (total); 0.28145 (align); 1.99861 (contra)
2025-11-05 04:16:40,418: New best model saved (epoch 14) with val_loss=2.430324
2025-11-05 04:16:50,193: Finish train epoch 15 in 9.78 seconds.
2025-11-05 04:16:50,194: Loss(train): 2.40871 (total); 0.28585 (align); 1.95893 (contra)
2025-11-05 04:16:50,194: Loss(validation): 2.43067 (total); 0.28498 (align); 2.01153 (contra)
2025-11-05 04:16:50,195: Loss(test): 2.40813 (total); 0.27914 (align); 2.02488 (contra)
2025-11-05 04:16:59,878: Finish train epoch 16 in 9.68 seconds.
2025-11-05 04:16:59,879: Loss(train): 2.39713 (total); 0.28316 (align); 1.96261 (contra)
2025-11-05 04:16:59,879: Loss(validation): 2.42714 (total); 0.28609 (align); 1.99335 (contra)
2025-11-05 04:16:59,879: Loss(test): 2.40541 (total); 0.28156 (align); 1.99527 (contra)
2025-11-05 04:16:59,974: New best model saved (epoch 16) with val_loss=2.427141
2025-11-05 04:17:09,676: Finish train epoch 17 in 9.70 seconds.
2025-11-05 04:17:09,677: Loss(train): 2.39655 (total); 0.28258 (align); 1.96732 (contra)
2025-11-05 04:17:09,677: Loss(validation): 2.43714 (total); 0.28593 (align); 2.01493 (contra)
2025-11-05 04:17:09,678: Loss(test): 2.39808 (total); 0.27798 (align); 2.01637 (contra)
2025-11-05 04:17:19,353: Finish train epoch 18 in 9.68 seconds.
2025-11-05 04:17:19,354: Loss(train): 2.38904 (total); 0.28123 (align); 1.96575 (contra)
2025-11-05 04:17:19,355: Loss(validation): 2.42255 (total); 0.28573 (align); 1.98778 (contra)
2025-11-05 04:17:19,355: Loss(test): 2.38765 (total); 0.27872 (align); 1.98807 (contra)
2025-11-05 04:17:19,455: New best model saved (epoch 18) with val_loss=2.422550
2025-11-05 04:17:29,217: Finish train epoch 19 in 9.76 seconds.
2025-11-05 04:17:29,218: Loss(train): 2.37862 (total); 0.27911 (align); 1.96615 (contra)
2025-11-05 04:17:29,218: Loss(validation): 2.44595 (total); 0.28932 (align); 1.99871 (contra)
2025-11-05 04:17:29,218: Loss(test): 2.39818 (total); 0.27922 (align); 2.00415 (contra)
2025-11-05 04:17:38,967: Finish train epoch 20 in 9.75 seconds.
2025-11-05 04:17:38,968: Loss(train): 2.39423 (total); 0.28090 (align); 1.97946 (contra)
2025-11-05 04:17:38,968: Loss(validation): 2.39424 (total); 0.28140 (align); 1.97450 (contra)
2025-11-05 04:17:38,968: Loss(test): 2.35778 (total); 0.27407 (align); 1.97487 (contra)
2025-11-05 04:17:39,071: New best model saved (epoch 20) with val_loss=2.394240
2025-11-05 04:17:48,706: Finish train epoch 21 in 9.63 seconds.
2025-11-05 04:17:48,706: Loss(train): 2.37234 (total); 0.27734 (align); 1.97131 (contra)
2025-11-05 04:17:48,707: Loss(validation): 2.41972 (total); 0.28602 (align); 1.97926 (contra)
2025-11-05 04:17:48,707: Loss(test): 2.38817 (total); 0.27899 (align); 1.98647 (contra)
2025-11-05 04:17:58,352: Finish train epoch 22 in 9.64 seconds.
2025-11-05 04:17:58,353: Loss(train): 2.36159 (total); 0.27556 (align); 1.96753 (contra)
2025-11-05 04:17:58,353: Loss(validation): 2.37860 (total); 0.27594 (align); 1.99776 (contra)
2025-11-05 04:17:58,353: Loss(test): 2.37321 (total); 0.27329 (align); 2.01355 (contra)
2025-11-05 04:17:58,449: New best model saved (epoch 22) with val_loss=2.378601
2025-11-05 04:18:08,145: Finish train epoch 23 in 9.70 seconds.
2025-11-05 04:18:08,146: Loss(train): 2.36607 (total); 0.27615 (align); 1.97060 (contra)
2025-11-05 04:18:08,146: Loss(validation): 2.39179 (total); 0.27852 (align); 1.99839 (contra)
2025-11-05 04:18:08,146: Loss(test): 2.35539 (total); 0.27044 (align); 2.00634 (contra)
2025-11-05 04:18:17,847: Finish train epoch 24 in 9.70 seconds.
2025-11-05 04:18:17,847: Loss(train): 2.34627 (total); 0.27213 (align); 1.97128 (contra)
2025-11-05 04:18:17,847: Loss(validation): 2.36856 (total); 0.27554 (align); 1.98168 (contra)
2025-11-05 04:18:17,848: Loss(test): 2.34543 (total); 0.27067 (align); 1.98412 (contra)
2025-11-05 04:18:17,955: New best model saved (epoch 24) with val_loss=2.368564
2025-11-05 04:18:27,733: Finish train epoch 25 in 9.78 seconds.
2025-11-05 04:18:27,734: Loss(train): 2.33545 (total); 0.26969 (align); 1.97396 (contra)
2025-11-05 04:18:27,734: Loss(validation): 2.37810 (total); 0.27664 (align); 1.98979 (contra)
2025-11-05 04:18:27,734: Loss(test): 2.33978 (total); 0.26864 (align); 1.99321 (contra)
2025-11-05 04:18:37,510: Finish train epoch 26 in 9.78 seconds.
2025-11-05 04:18:37,511: Loss(train): 2.33431 (total); 0.26987 (align); 1.96988 (contra)
2025-11-05 04:18:37,511: Loss(validation): 2.37570 (total); 0.27671 (align); 1.98436 (contra)
2025-11-05 04:18:37,511: Loss(test): 2.33165 (total); 0.26841 (align); 1.97921 (contra)
2025-11-05 04:18:47,238: Finish train epoch 27 in 9.73 seconds.
2025-11-05 04:18:47,239: Loss(train): 2.31478 (total); 0.26598 (align); 1.96978 (contra)
2025-11-05 04:18:47,240: Loss(validation): 2.37434 (total); 0.27522 (align); 1.99650 (contra)
2025-11-05 04:18:47,240: Loss(test): 2.33801 (total); 0.26838 (align); 1.99224 (contra)
2025-11-05 04:18:57,034: Finish train epoch 28 in 9.79 seconds.
2025-11-05 04:18:57,034: Loss(train): 2.34834 (total); 0.27210 (align); 1.97567 (contra)
2025-11-05 04:18:57,035: Loss(validation): 2.37289 (total); 0.27703 (align); 1.97551 (contra)
2025-11-05 04:18:57,035: Loss(test): 2.31721 (total); 0.26501 (align); 1.98428 (contra)
2025-11-05 04:19:06,806: Finish train epoch 29 in 9.77 seconds.
2025-11-05 04:19:06,806: Loss(train): 2.30999 (total); 0.26450 (align); 1.97496 (contra)
2025-11-05 04:19:06,807: Loss(validation): 2.35563 (total); 0.27311 (align); 1.98012 (contra)
2025-11-05 04:19:06,807: Loss(test): 2.28811 (total); 0.25937 (align); 1.98255 (contra)
2025-11-05 04:19:06,920: New best model saved (epoch 29) with val_loss=2.355628
2025-11-05 04:19:16,775: Finish train epoch 30 in 9.85 seconds.
2025-11-05 04:19:16,776: Loss(train): 2.31706 (total); 0.26595 (align); 1.97460 (contra)
2025-11-05 04:19:16,776: Loss(validation): 2.36827 (total); 0.27706 (align); 1.96592 (contra)
2025-11-05 04:19:16,776: Loss(test): 2.32286 (total); 0.26773 (align); 1.96847 (contra)
2025-11-05 04:19:26,651: Finish train epoch 31 in 9.87 seconds.
2025-11-05 04:19:26,652: Loss(train): 2.28824 (total); 0.26035 (align); 1.97298 (contra)
2025-11-05 04:19:26,652: Loss(validation): 2.33874 (total); 0.27026 (align); 1.97489 (contra)
2025-11-05 04:19:26,652: Loss(test): 2.26691 (total); 0.25503 (align); 1.98356 (contra)
2025-11-05 04:19:26,754: New best model saved (epoch 31) with val_loss=2.338735
2025-11-05 04:19:36,418: Finish train epoch 32 in 9.66 seconds.
2025-11-05 04:19:36,419: Loss(train): 2.30353 (total); 0.26369 (align); 1.97017 (contra)
2025-11-05 04:19:36,419: Loss(validation): 2.37241 (total); 0.27629 (align); 1.98190 (contra)
2025-11-05 04:19:36,419: Loss(test): 2.33086 (total); 0.26824 (align); 1.97935 (contra)
2025-11-05 04:19:46,089: Finish train epoch 33 in 9.67 seconds.
2025-11-05 04:19:46,090: Loss(train): 2.27429 (total); 0.25799 (align); 1.96864 (contra)
2025-11-05 04:19:46,090: Loss(validation): 2.32895 (total); 0.26560 (align); 2.00195 (contra)
2025-11-05 04:19:46,090: Loss(test): 2.28847 (total); 0.25627 (align); 2.01422 (contra)
2025-11-05 04:19:46,194: New best model saved (epoch 33) with val_loss=2.328954
2025-11-05 04:19:55,885: Finish train epoch 34 in 9.69 seconds.
2025-11-05 04:19:55,886: Loss(train): 2.23357 (total); 0.24984 (align); 1.96878 (contra)
2025-11-05 04:19:55,886: Loss(validation): 2.30265 (total); 0.26305 (align); 1.97478 (contra)
2025-11-05 04:19:55,886: Loss(test): 2.25659 (total); 0.25340 (align); 1.97916 (contra)
2025-11-05 04:19:55,981: New best model saved (epoch 34) with val_loss=2.302648
2025-11-05 04:20:05,731: Finish train epoch 35 in 9.75 seconds.
2025-11-05 04:20:05,732: Loss(train): 2.23386 (total); 0.24991 (align); 1.96860 (contra)
2025-11-05 04:20:05,732: Loss(validation): 2.27621 (total); 0.25751 (align); 1.97733 (contra)
2025-11-05 04:20:05,733: Loss(test): 2.21142 (total); 0.24529 (align); 1.96997 (contra)
2025-11-05 04:20:05,843: New best model saved (epoch 35) with val_loss=2.276206
2025-11-05 04:20:15,516: Finish train epoch 36 in 9.67 seconds.
2025-11-05 04:20:15,517: Loss(train): 2.21247 (total); 0.24582 (align); 1.96678 (contra)
2025-11-05 04:20:15,517: Loss(validation): 2.30724 (total); 0.26388 (align); 1.97573 (contra)
2025-11-05 04:20:15,517: Loss(test): 2.20507 (total); 0.24330 (align); 1.97712 (contra)
2025-11-05 04:20:25,173: Finish train epoch 37 in 9.66 seconds.
2025-11-05 04:20:25,174: Loss(train): 2.19426 (total); 0.24179 (align); 1.97057 (contra)
2025-11-05 04:20:25,174: Loss(validation): 2.25671 (total); 0.25354 (align); 1.97806 (contra)
2025-11-05 04:20:25,174: Loss(test): 2.19104 (total); 0.24029 (align); 1.97921 (contra)
2025-11-05 04:20:25,273: New best model saved (epoch 37) with val_loss=2.256714
2025-11-05 04:20:34,945: Finish train epoch 38 in 9.67 seconds.
2025-11-05 04:20:34,946: Loss(train): 2.20455 (total); 0.24372 (align); 1.97191 (contra)
2025-11-05 04:20:34,947: Loss(validation): 2.29681 (total); 0.25954 (align); 1.99820 (contra)
2025-11-05 04:20:34,947: Loss(test): 2.22824 (total); 0.24446 (align); 2.01192 (contra)
2025-11-05 04:20:44,604: Finish train epoch 39 in 9.66 seconds.
2025-11-05 04:20:44,605: Loss(train): 2.17080 (total); 0.23709 (align); 1.97071 (contra)
2025-11-05 04:20:44,605: Loss(validation): 2.28976 (total); 0.25887 (align); 1.99084 (contra)
2025-11-05 04:20:44,605: Loss(test): 2.16521 (total); 0.23357 (align); 1.99475 (contra)
2025-11-05 04:20:54,230: Finish train epoch 40 in 9.62 seconds.
2025-11-05 04:20:54,231: Loss(train): 2.16895 (total); 0.23648 (align); 1.97311 (contra)
2025-11-05 04:20:54,231: Loss(validation): 2.31408 (total); 0.26042 (align); 2.02396 (contra)
2025-11-05 04:20:54,231: Loss(test): 2.23808 (total); 0.24464 (align); 2.02974 (contra)
2025-11-05 04:21:03,860: Finish train epoch 41 in 9.63 seconds.
2025-11-05 04:21:03,861: Loss(train): 2.17656 (total); 0.23792 (align); 1.97393 (contra)
2025-11-05 04:21:03,861: Loss(validation): 2.22201 (total); 0.24538 (align); 1.99020 (contra)
2025-11-05 04:21:03,862: Loss(test): 2.16290 (total); 0.23389 (align); 1.98688 (contra)
2025-11-05 04:21:03,960: New best model saved (epoch 41) with val_loss=2.222015
2025-11-05 04:21:13,596: Finish train epoch 42 in 9.64 seconds.
2025-11-05 04:21:13,597: Loss(train): 2.15327 (total); 0.23358 (align); 1.97075 (contra)
2025-11-05 04:21:13,597: Loss(validation): 2.21391 (total); 0.24472 (align); 1.98064 (contra)
2025-11-05 04:21:13,597: Loss(test): 2.16497 (total); 0.23482 (align); 1.98170 (contra)
2025-11-05 04:21:13,699: New best model saved (epoch 42) with val_loss=2.213912
2025-11-05 04:21:23,399: Finish train epoch 43 in 9.70 seconds.
2025-11-05 04:21:23,400: Loss(train): 2.13048 (total); 0.22937 (align); 1.96726 (contra)
2025-11-05 04:21:23,400: Loss(validation): 2.18862 (total); 0.23929 (align); 1.98435 (contra)
2025-11-05 04:21:23,400: Loss(test): 2.15453 (total); 0.23178 (align); 1.99122 (contra)
2025-11-05 04:21:23,493: New best model saved (epoch 43) with val_loss=2.188617
2025-11-05 04:21:33,244: Finish train epoch 44 in 9.75 seconds.
2025-11-05 04:21:33,244: Loss(train): 2.08174 (total); 0.21945 (align); 1.96902 (contra)
2025-11-05 04:21:33,245: Loss(validation): 2.25017 (total); 0.25245 (align); 1.97580 (contra)
2025-11-05 04:21:33,245: Loss(test): 2.11549 (total); 0.22552 (align); 1.97576 (contra)
2025-11-05 04:21:42,890: Finish train epoch 45 in 9.65 seconds.
2025-11-05 04:21:42,891: Loss(train): 2.07238 (total); 0.21754 (align); 1.96935 (contra)
2025-11-05 04:21:42,891: Loss(validation): 2.18427 (total); 0.23811 (align); 1.98746 (contra)
2025-11-05 04:21:42,892: Loss(test): 2.11754 (total); 0.22439 (align); 1.99116 (contra)
2025-11-05 04:21:42,986: New best model saved (epoch 45) with val_loss=2.184274
2025-11-05 04:21:52,742: Finish train epoch 46 in 9.76 seconds.
2025-11-05 04:21:52,743: Loss(train): 2.04280 (total); 0.21175 (align); 1.96805 (contra)
2025-11-05 04:21:52,743: Loss(validation): 2.20805 (total); 0.24269 (align); 1.98923 (contra)
2025-11-05 04:21:52,743: Loss(test): 2.19154 (total); 0.24054 (align); 1.97763 (contra)
2025-11-05 04:22:02,414: Finish train epoch 47 in 9.67 seconds.
2025-11-05 04:22:02,414: Loss(train): 2.02659 (total); 0.20837 (align); 1.96952 (contra)
2025-11-05 04:22:02,415: Loss(validation): 2.11333 (total); 0.22495 (align); 1.97719 (contra)
2025-11-05 04:22:02,415: Loss(test): 2.02558 (total); 0.20767 (align); 1.97445 (contra)
2025-11-05 04:22:02,512: New best model saved (epoch 47) with val_loss=2.113326
2025-11-05 04:22:12,246: Finish train epoch 48 in 9.73 seconds.
2025-11-05 04:22:12,247: Loss(train): 1.98719 (total); 0.20062 (align); 1.96816 (contra)
2025-11-05 04:22:12,247: Loss(validation): 2.11992 (total); 0.22680 (align); 1.97181 (contra)
2025-11-05 04:22:12,247: Loss(test): 2.06552 (total); 0.21540 (align); 1.97704 (contra)
2025-11-05 04:22:21,910: Finish train epoch 49 in 9.66 seconds.
2025-11-05 04:22:21,911: Loss(train): 1.98188 (total); 0.19970 (align); 1.96671 (contra)
2025-11-05 04:22:21,911: Loss(validation): 2.16126 (total); 0.23445 (align); 1.97800 (contra)
2025-11-05 04:22:21,911: Loss(test): 2.10656 (total); 0.22365 (align); 1.97666 (contra)
2025-11-05 04:22:22,322: Saved test embeddings to /mnt/afs/250010218/multi-level-Chinese-decoding/train/duin/../../summaries/2025-11-05/4/train/ckpt/test_embeddings_epoch_050.npy
2025-11-05 04:22:32,039: Finish train epoch 50 in 9.72 seconds.
2025-11-05 04:22:32,039: Loss(train): 1.93155 (total); 0.18982 (align); 1.96487 (contra)
2025-11-05 04:22:32,039: Loss(validation): 2.13309 (total); 0.22675 (align); 1.99871 (contra)
2025-11-05 04:22:32,040: Loss(test): 2.04100 (total); 0.20746 (align); 2.00737 (contra)
2025-11-05 04:22:41,787: Finish train epoch 51 in 9.75 seconds.
2025-11-05 04:22:41,788: Loss(train): 1.94219 (total); 0.19166 (align); 1.96782 (contra)
2025-11-05 04:22:41,788: Loss(validation): 2.06919 (total); 0.21576 (align); 1.98082 (contra)
2025-11-05 04:22:41,788: Loss(test): 2.01117 (total); 0.20354 (align); 1.98696 (contra)
2025-11-05 04:22:41,886: New best model saved (epoch 51) with val_loss=2.069187
2025-11-05 04:22:51,620: Finish train epoch 52 in 9.73 seconds.
2025-11-05 04:22:51,620: Loss(train): 1.91211 (total); 0.18573 (align); 1.96696 (contra)
2025-11-05 04:22:51,621: Loss(validation): 2.10541 (total); 0.22352 (align); 1.97562 (contra)
2025-11-05 04:22:51,621: Loss(test): 2.02877 (total); 0.20881 (align); 1.96944 (contra)
2025-11-05 04:23:01,423: Finish train epoch 53 in 9.80 seconds.
2025-11-05 04:23:01,424: Loss(train): 1.89171 (total); 0.18154 (align); 1.96802 (contra)
2025-11-05 04:23:01,424: Loss(validation): 2.06604 (total); 0.21564 (align); 1.97569 (contra)
2025-11-05 04:23:01,424: Loss(test): 1.94122 (total); 0.19107 (align); 1.97172 (contra)
2025-11-05 04:23:01,520: New best model saved (epoch 53) with val_loss=2.066036
2025-11-05 04:23:11,289: Finish train epoch 54 in 9.77 seconds.
2025-11-05 04:23:11,290: Loss(train): 1.88502 (total); 0.18010 (align); 1.96901 (contra)
2025-11-05 04:23:11,290: Loss(validation): 2.02289 (total); 0.20709 (align); 1.97492 (contra)
2025-11-05 04:23:11,290: Loss(test): 2.03267 (total); 0.20862 (align); 1.97916 (contra)
2025-11-05 04:23:11,399: New best model saved (epoch 54) with val_loss=2.022888
2025-11-05 04:23:21,146: Finish train epoch 55 in 9.75 seconds.
2025-11-05 04:23:21,147: Loss(train): 1.81994 (total); 0.16755 (align); 1.96442 (contra)
2025-11-05 04:23:21,147: Loss(validation): 2.03068 (total); 0.20777 (align); 1.98369 (contra)
2025-11-05 04:23:21,147: Loss(test): 1.97978 (total); 0.19685 (align); 1.99104 (contra)
2025-11-05 04:23:30,980: Finish train epoch 56 in 9.83 seconds.
2025-11-05 04:23:30,981: Loss(train): 1.76989 (total); 0.15722 (align); 1.96754 (contra)
2025-11-05 04:23:30,981: Loss(validation): 2.00802 (total); 0.20305 (align); 1.98552 (contra)
2025-11-05 04:23:30,981: Loss(test): 1.91664 (total); 0.18507 (align); 1.98260 (contra)
2025-11-05 04:23:31,098: New best model saved (epoch 56) with val_loss=2.008025
2025-11-05 04:23:40,962: Finish train epoch 57 in 9.86 seconds.
2025-11-05 04:23:40,963: Loss(train): 1.77692 (total); 0.15881 (align); 1.96573 (contra)
2025-11-05 04:23:40,963: Loss(validation): 1.97466 (total); 0.19596 (align); 1.98973 (contra)
2025-11-05 04:23:40,963: Loss(test): 1.91831 (total); 0.18446 (align); 1.99207 (contra)
2025-11-05 04:23:41,069: New best model saved (epoch 57) with val_loss=1.974656
2025-11-05 04:23:50,917: Finish train epoch 58 in 9.85 seconds.
2025-11-05 04:23:50,918: Loss(train): 1.74353 (total); 0.15224 (align); 1.96464 (contra)
2025-11-05 04:23:50,918: Loss(validation): 1.99918 (total); 0.20114 (align); 1.98698 (contra)
2025-11-05 04:23:50,918: Loss(test): 1.91908 (total); 0.18475 (align); 1.99066 (contra)
2025-11-05 04:24:00,776: Finish train epoch 59 in 9.86 seconds.
2025-11-05 04:24:00,777: Loss(train): 1.73315 (total); 0.14987 (align); 1.96761 (contra)
2025-11-05 04:24:00,777: Loss(validation): 1.97938 (total); 0.19800 (align); 1.97876 (contra)
2025-11-05 04:24:00,778: Loss(test): 1.89910 (total); 0.18134 (align); 1.98476 (contra)
2025-11-05 04:24:10,504: Finish train epoch 60 in 9.73 seconds.
2025-11-05 04:24:10,506: Loss(train): 1.68285 (total); 0.14000 (align); 1.96575 (contra)
2025-11-05 04:24:10,506: Loss(validation): 1.99205 (total); 0.20009 (align); 1.98317 (contra)
2025-11-05 04:24:10,506: Loss(test): 1.91905 (total); 0.18505 (align); 1.98757 (contra)
2025-11-05 04:24:20,242: Finish train epoch 61 in 9.74 seconds.
2025-11-05 04:24:20,243: Loss(train): 1.59071 (total); 0.12196 (align); 1.96178 (contra)
2025-11-05 04:24:20,243: Loss(validation): 2.00286 (total); 0.20197 (align); 1.98601 (contra)
2025-11-05 04:24:20,243: Loss(test): 1.90506 (total); 0.18269 (align); 1.98324 (contra)
2025-11-05 04:24:29,923: Finish train epoch 62 in 9.68 seconds.
2025-11-05 04:24:29,924: Loss(train): 1.61648 (total); 0.12661 (align); 1.96690 (contra)
2025-11-05 04:24:29,924: Loss(validation): 1.98208 (total); 0.19808 (align); 1.98333 (contra)
2025-11-05 04:24:29,924: Loss(test): 1.88366 (total); 0.17939 (align); 1.97337 (contra)
2025-11-05 04:24:39,557: Finish train epoch 63 in 9.63 seconds.
2025-11-05 04:24:39,558: Loss(train): 1.59947 (total); 0.12363 (align); 1.96263 (contra)
2025-11-05 04:24:39,558: Loss(validation): 1.94766 (total); 0.19079 (align); 1.98740 (contra)
2025-11-05 04:24:39,558: Loss(test): 1.86410 (total); 0.17461 (align); 1.98211 (contra)
2025-11-05 04:24:39,660: New best model saved (epoch 63) with val_loss=1.947663
2025-11-05 04:24:49,381: Finish train epoch 64 in 9.72 seconds.
2025-11-05 04:24:49,382: Loss(train): 1.55320 (total); 0.11429 (align); 1.96353 (contra)
2025-11-05 04:24:49,382: Loss(validation): 1.83484 (total); 0.16998 (align); 1.96988 (contra)
2025-11-05 04:24:49,382: Loss(test): 1.82202 (total); 0.16710 (align); 1.97305 (contra)
2025-11-05 04:24:49,491: New best model saved (epoch 64) with val_loss=1.834841
2025-11-05 04:24:59,375: Finish train epoch 65 in 9.88 seconds.
2025-11-05 04:24:59,376: Loss(train): 1.53434 (total); 0.11063 (align); 1.96234 (contra)
2025-11-05 04:24:59,376: Loss(validation): 1.83107 (total); 0.16868 (align); 1.97535 (contra)
2025-11-05 04:24:59,376: Loss(test): 1.80249 (total); 0.16235 (align); 1.98148 (contra)
2025-11-05 04:24:59,481: New best model saved (epoch 65) with val_loss=1.831068
2025-11-05 04:25:09,260: Finish train epoch 66 in 9.78 seconds.
2025-11-05 04:25:09,261: Loss(train): 1.56551 (total); 0.11642 (align); 1.96686 (contra)
2025-11-05 04:25:09,262: Loss(validation): 1.90580 (total); 0.18213 (align); 1.99026 (contra)
2025-11-05 04:25:09,262: Loss(test): 1.87524 (total); 0.17590 (align); 1.99144 (contra)
2025-11-05 04:25:18,925: Finish train epoch 67 in 9.66 seconds.
2025-11-05 04:25:18,926: Loss(train): 1.50499 (total); 0.10504 (align); 1.95962 (contra)
2025-11-05 04:25:18,926: Loss(validation): 1.77330 (total); 0.15773 (align); 1.96926 (contra)
2025-11-05 04:25:18,926: Loss(test): 1.78961 (total); 0.16071 (align); 1.97214 (contra)
2025-11-05 04:25:19,026: New best model saved (epoch 67) with val_loss=1.773302
2025-11-05 04:25:28,636: Finish train epoch 68 in 9.61 seconds.
2025-11-05 04:25:28,637: Loss(train): 1.50993 (total); 0.10564 (align); 1.96345 (contra)
2025-11-05 04:25:28,637: Loss(validation): 1.82214 (total); 0.16739 (align); 1.97037 (contra)
2025-11-05 04:25:28,637: Loss(test): 1.76921 (total); 0.15654 (align); 1.97304 (contra)
2025-11-05 04:25:38,297: Finish train epoch 69 in 9.66 seconds.
2025-11-05 04:25:38,298: Loss(train): 1.46294 (total); 0.09643 (align); 1.96155 (contra)
2025-11-05 04:25:38,298: Loss(validation): 1.83178 (total); 0.16925 (align); 1.97111 (contra)
2025-11-05 04:25:38,298: Loss(test): 1.70920 (total); 0.14436 (align); 1.97483 (contra)
2025-11-05 04:25:47,912: Finish train epoch 70 in 9.61 seconds.
2025-11-05 04:25:47,913: Loss(train): 1.41374 (total); 0.08662 (align); 1.96127 (contra)
2025-11-05 04:25:47,913: Loss(validation): 1.74995 (total); 0.15261 (align); 1.97375 (contra)
2025-11-05 04:25:47,913: Loss(test): 1.77245 (total); 0.15653 (align); 1.97960 (contra)
2025-11-05 04:25:48,014: New best model saved (epoch 70) with val_loss=1.749947
2025-11-05 04:25:57,679: Finish train epoch 71 in 9.66 seconds.
2025-11-05 04:25:57,680: Loss(train): 1.38729 (total); 0.08118 (align); 1.96279 (contra)
2025-11-05 04:25:57,680: Loss(validation): 1.80660 (total); 0.16412 (align); 1.97205 (contra)
2025-11-05 04:25:57,680: Loss(test): 1.74413 (total); 0.15153 (align); 1.97292 (contra)
2025-11-05 04:26:07,285: Finish train epoch 72 in 9.61 seconds.
2025-11-05 04:26:07,286: Loss(train): 1.38349 (total); 0.08048 (align); 1.96215 (contra)
2025-11-05 04:26:07,286: Loss(validation): 1.75226 (total); 0.15239 (align); 1.98062 (contra)
2025-11-05 04:26:07,286: Loss(test): 1.70521 (total); 0.14399 (align); 1.97057 (contra)
2025-11-05 04:26:16,973: Finish train epoch 73 in 9.69 seconds.
2025-11-05 04:26:16,973: Loss(train): 1.37395 (total); 0.07868 (align); 1.96106 (contra)
2025-11-05 04:26:16,973: Loss(validation): 1.75325 (total); 0.15343 (align); 1.97218 (contra)
2025-11-05 04:26:16,974: Loss(test): 1.68486 (total); 0.13944 (align); 1.97529 (contra)
2025-11-05 04:26:26,640: Finish train epoch 74 in 9.67 seconds.
2025-11-05 04:26:26,641: Loss(train): 1.33502 (total); 0.07099 (align); 1.96011 (contra)
2025-11-05 04:26:26,641: Loss(validation): 1.72999 (total); 0.14911 (align); 1.96891 (contra)
2025-11-05 04:26:26,641: Loss(test): 1.68264 (total); 0.13863 (align); 1.97899 (contra)
2025-11-05 04:26:26,737: New best model saved (epoch 74) with val_loss=1.729986
2025-11-05 04:26:36,388: Finish train epoch 75 in 9.65 seconds.
2025-11-05 04:26:36,388: Loss(train): 1.31341 (total); 0.06677 (align); 1.95912 (contra)
2025-11-05 04:26:36,389: Loss(validation): 1.79379 (total); 0.16041 (align); 1.98345 (contra)
2025-11-05 04:26:36,389: Loss(test): 1.73772 (total); 0.14988 (align); 1.97669 (contra)
2025-11-05 04:26:46,185: Finish train epoch 76 in 9.80 seconds.
2025-11-05 04:26:46,185: Loss(train): 1.30851 (total); 0.06561 (align); 1.96092 (contra)
2025-11-05 04:26:46,185: Loss(validation): 1.67697 (total); 0.13890 (align); 1.96499 (contra)
2025-11-05 04:26:46,186: Loss(test): 1.60764 (total); 0.12516 (align); 1.96366 (contra)
2025-11-05 04:26:46,284: New best model saved (epoch 76) with val_loss=1.676969
2025-11-05 04:26:55,954: Finish train epoch 77 in 9.67 seconds.
2025-11-05 04:26:55,955: Loss(train): 1.27457 (total); 0.05888 (align); 1.96029 (contra)
2025-11-05 04:26:55,955: Loss(validation): 1.72473 (total); 0.14766 (align); 1.97282 (contra)
2025-11-05 04:26:55,955: Loss(test): 1.62494 (total); 0.12846 (align); 1.96527 (contra)
2025-11-05 04:27:05,597: Finish train epoch 78 in 9.64 seconds.
2025-11-05 04:27:05,598: Loss(train): 1.29786 (total); 0.06337 (align); 1.96199 (contra)
2025-11-05 04:27:05,598: Loss(validation): 1.79278 (total); 0.16108 (align); 1.97480 (contra)
2025-11-05 04:27:05,598: Loss(test): 1.69665 (total); 0.14156 (align); 1.97766 (contra)
2025-11-05 04:27:15,225: Finish train epoch 79 in 9.63 seconds.
2025-11-05 04:27:15,225: Loss(train): 1.28400 (total); 0.06079 (align); 1.96012 (contra)
2025-11-05 04:27:15,226: Loss(validation): 1.83984 (total); 0.17049 (align); 1.97473 (contra)
2025-11-05 04:27:15,226: Loss(test): 1.69777 (total); 0.14158 (align); 1.97974 (contra)
2025-11-05 04:27:24,806: Finish train epoch 80 in 9.58 seconds.
2025-11-05 04:27:24,807: Loss(train): 1.27444 (total); 0.05917 (align); 1.95717 (contra)
2025-11-05 04:27:24,807: Loss(validation): 1.76369 (total); 0.15525 (align); 1.97486 (contra)
2025-11-05 04:27:24,807: Loss(test): 1.61489 (total); 0.12623 (align); 1.96742 (contra)
2025-11-05 04:27:34,421: Finish train epoch 81 in 9.61 seconds.
2025-11-05 04:27:34,422: Loss(train): 1.25471 (total); 0.05503 (align); 1.95917 (contra)
2025-11-05 04:27:34,422: Loss(validation): 1.80298 (total); 0.16386 (align); 1.96736 (contra)
2025-11-05 04:27:34,422: Loss(test): 1.70064 (total); 0.14284 (align); 1.97293 (contra)
2025-11-05 04:27:44,005: Finish train epoch 82 in 9.58 seconds.
2025-11-05 04:27:44,005: Loss(train): 1.25142 (total); 0.05394 (align); 1.96349 (contra)
2025-11-05 04:27:44,006: Loss(validation): 1.81153 (total); 0.16483 (align); 1.97477 (contra)
2025-11-05 04:27:44,006: Loss(test): 1.72807 (total); 0.14821 (align); 1.97404 (contra)
2025-11-05 04:27:53,584: Finish train epoch 83 in 9.58 seconds.
2025-11-05 04:27:53,584: Loss(train): 1.19067 (total); 0.04234 (align); 1.95792 (contra)
2025-11-05 04:27:53,585: Loss(validation): 1.69863 (total); 0.14338 (align); 1.96345 (contra)
2025-11-05 04:27:53,585: Loss(test): 1.62091 (total); 0.12742 (align); 1.96759 (contra)
2025-11-05 04:28:03,299: Finish train epoch 84 in 9.71 seconds.
2025-11-05 04:28:03,300: Loss(train): 1.22734 (total); 0.04955 (align); 1.95917 (contra)
2025-11-05 04:28:03,300: Loss(validation): 1.72913 (total); 0.14827 (align); 1.97554 (contra)
2025-11-05 04:28:03,301: Loss(test): 1.67958 (total); 0.13761 (align); 1.98302 (contra)
2025-11-05 04:28:13,163: Finish train epoch 85 in 9.86 seconds.
2025-11-05 04:28:13,164: Loss(train): 1.21985 (total); 0.04823 (align); 1.95740 (contra)
2025-11-05 04:28:13,164: Loss(validation): 1.71665 (total); 0.14588 (align); 1.97448 (contra)
2025-11-05 04:28:13,165: Loss(test): 1.70073 (total); 0.14281 (align); 1.97332 (contra)
2025-11-05 04:28:22,851: Finish train epoch 86 in 9.69 seconds.
2025-11-05 04:28:22,852: Loss(train): 1.22195 (total); 0.04861 (align); 1.95775 (contra)
2025-11-05 04:28:22,852: Loss(validation): 1.73746 (total); 0.15035 (align); 1.97138 (contra)
2025-11-05 04:28:22,853: Loss(test): 1.59555 (total); 0.12192 (align); 1.97190 (contra)
2025-11-05 04:28:32,560: Finish train epoch 87 in 9.71 seconds.
2025-11-05 04:28:32,561: Loss(train): 1.17967 (total); 0.04035 (align); 1.95582 (contra)
2025-11-05 04:28:32,561: Loss(validation): 1.72960 (total); 0.14898 (align); 1.96938 (contra)
2025-11-05 04:28:32,561: Loss(test): 1.60933 (total); 0.12468 (align); 1.97187 (contra)
2025-11-05 04:28:42,252: Finish train epoch 88 in 9.69 seconds.
2025-11-05 04:28:42,252: Loss(train): 1.16080 (total); 0.03656 (align); 1.95599 (contra)
2025-11-05 04:28:42,253: Loss(validation): 1.70956 (total); 0.14477 (align); 1.97142 (contra)
2025-11-05 04:28:42,253: Loss(test): 1.56172 (total); 0.11536 (align); 1.96981 (contra)
2025-11-05 04:28:51,975: Finish train epoch 89 in 9.72 seconds.
2025-11-05 04:28:51,976: Loss(train): 1.15530 (total); 0.03526 (align); 1.95800 (contra)
2025-11-05 04:28:51,976: Loss(validation): 1.67506 (total); 0.13777 (align); 1.97243 (contra)
2025-11-05 04:28:51,976: Loss(test): 1.59177 (total); 0.12082 (align); 1.97530 (contra)
2025-11-05 04:28:52,074: New best model saved (epoch 89) with val_loss=1.675057
2025-11-05 04:29:01,755: Finish train epoch 90 in 9.68 seconds.
2025-11-05 04:29:01,756: Loss(train): 1.16777 (total); 0.03767 (align); 1.95886 (contra)
2025-11-05 04:29:01,756: Loss(validation): 1.79585 (total); 0.16129 (align); 1.97875 (contra)
2025-11-05 04:29:01,756: Loss(test): 1.68339 (total); 0.13817 (align); 1.98507 (contra)
2025-11-05 04:29:11,392: Finish train epoch 91 in 9.64 seconds.
2025-11-05 04:29:11,393: Loss(train): 1.17587 (total); 0.03922 (align); 1.95957 (contra)
2025-11-05 04:29:11,393: Loss(validation): 1.70259 (total); 0.14305 (align); 1.97472 (contra)
2025-11-05 04:29:11,393: Loss(test): 1.64584 (total); 0.13202 (align); 1.97153 (contra)
2025-11-05 04:29:21,111: Finish train epoch 92 in 9.72 seconds.
2025-11-05 04:29:21,112: Loss(train): 1.14897 (total); 0.03406 (align); 1.95732 (contra)
2025-11-05 04:29:21,112: Loss(validation): 1.71687 (total); 0.14572 (align); 1.97655 (contra)
2025-11-05 04:29:21,112: Loss(test): 1.68839 (total); 0.14002 (align); 1.97656 (contra)
2025-11-05 04:29:31,154: Finish train epoch 93 in 10.04 seconds.
2025-11-05 04:29:31,155: Loss(train): 1.23113 (total); 0.05011 (align); 1.96116 (contra)
2025-11-05 04:29:31,155: Loss(validation): 1.72276 (total); 0.14730 (align); 1.97249 (contra)
2025-11-05 04:29:31,155: Loss(test): 1.62129 (total); 0.12667 (align); 1.97586 (contra)
2025-11-05 04:29:41,082: Finish train epoch 94 in 9.93 seconds.
2025-11-05 04:29:41,083: Loss(train): 1.17900 (total); 0.04000 (align); 1.95801 (contra)
2025-11-05 04:29:41,084: Loss(validation): 1.68426 (total); 0.14075 (align); 1.96098 (contra)
2025-11-05 04:29:41,084: Loss(test): 1.58548 (total); 0.12004 (align); 1.97052 (contra)
2025-11-05 04:29:50,653: Finish train epoch 95 in 9.57 seconds.
2025-11-05 04:29:50,654: Loss(train): 1.19456 (total); 0.04294 (align); 1.95968 (contra)
2025-11-05 04:29:50,654: Loss(validation): 1.68181 (total); 0.13909 (align); 1.97269 (contra)
2025-11-05 04:29:50,654: Loss(test): 1.64887 (total); 0.13225 (align); 1.97527 (contra)
2025-11-05 04:30:00,221: Finish train epoch 96 in 9.57 seconds.
2025-11-05 04:30:00,222: Loss(train): 1.19502 (total); 0.04311 (align); 1.95890 (contra)
2025-11-05 04:30:00,222: Loss(validation): 1.76610 (total); 0.15642 (align); 1.96801 (contra)
2025-11-05 04:30:00,222: Loss(test): 1.73167 (total); 0.14894 (align); 1.97397 (contra)
2025-11-05 04:30:09,853: Finish train epoch 97 in 9.63 seconds.
2025-11-05 04:30:09,854: Loss(train): 1.20949 (total); 0.04616 (align); 1.95740 (contra)
2025-11-05 04:30:09,854: Loss(validation): 1.75881 (total); 0.15414 (align); 1.97626 (contra)
2025-11-05 04:30:09,854: Loss(test): 1.67051 (total); 0.13665 (align); 1.97455 (contra)
2025-11-05 04:30:19,843: Finish train epoch 98 in 9.99 seconds.
2025-11-05 04:30:19,844: Loss(train): 1.14224 (total); 0.03261 (align); 1.95837 (contra)
2025-11-05 04:30:19,845: Loss(validation): 1.65524 (total); 0.13386 (align); 1.97191 (contra)
2025-11-05 04:30:19,845: Loss(test): 1.63785 (total); 0.13093 (align); 1.96643 (contra)
2025-11-05 04:30:19,991: New best model saved (epoch 98) with val_loss=1.655243
2025-11-05 04:30:30,237: Finish train epoch 99 in 10.25 seconds.
2025-11-05 04:30:30,239: Loss(train): 1.11928 (total); 0.02818 (align); 1.95679 (contra)
2025-11-05 04:30:30,239: Loss(validation): 1.71660 (total); 0.14623 (align); 1.97095 (contra)
2025-11-05 04:30:30,239: Loss(test): 1.63719 (total); 0.13055 (align); 1.96883 (contra)
2025-11-05 04:30:30,651: Saved test embeddings to /mnt/afs/250010218/multi-level-Chinese-decoding/train/duin/../../summaries/2025-11-05/4/train/ckpt/test_embeddings_epoch_100.npy
2025-11-05 04:30:41,042: Finish train epoch 100 in 10.39 seconds.
2025-11-05 04:30:41,043: Loss(train): 1.10650 (total); 0.02571 (align); 1.95589 (contra)
2025-11-05 04:30:41,043: Loss(validation): 1.65589 (total); 0.13472 (align); 1.96462 (contra)
2025-11-05 04:30:41,043: Loss(test): 1.62736 (total); 0.12853 (align); 1.96938 (contra)
2025-11-05 04:30:50,747: Finish train epoch 101 in 9.70 seconds.
2025-11-05 04:30:50,748: Loss(train): 1.07793 (total); 0.02015 (align); 1.95431 (contra)
2025-11-05 04:30:50,749: Loss(validation): 1.73498 (total); 0.15003 (align); 1.96970 (contra)
2025-11-05 04:30:50,749: Loss(test): 1.64295 (total); 0.13251 (align); 1.96079 (contra)
2025-11-05 04:31:00,454: Finish train epoch 102 in 9.70 seconds.
2025-11-05 04:31:00,455: Loss(train): 1.10748 (total); 0.02595 (align); 1.95544 (contra)
2025-11-05 04:31:00,455: Loss(validation): 1.67929 (total); 0.13969 (align); 1.96167 (contra)
2025-11-05 04:31:00,455: Loss(test): 1.57893 (total); 0.11978 (align); 1.96005 (contra)
2025-11-05 04:31:10,187: Finish train epoch 103 in 9.73 seconds.
2025-11-05 04:31:10,188: Loss(train): 1.07764 (total); 0.02006 (align); 1.95464 (contra)
2025-11-05 04:31:10,188: Loss(validation): 1.71781 (total); 0.14635 (align); 1.97216 (contra)
2025-11-05 04:31:10,188: Loss(test): 1.59601 (total); 0.12217 (align); 1.97029 (contra)
2025-11-05 04:31:20,009: Finish train epoch 104 in 9.82 seconds.
2025-11-05 04:31:20,010: Loss(train): 1.09943 (total); 0.02425 (align); 1.95640 (contra)
2025-11-05 04:31:20,010: Loss(validation): 1.72554 (total); 0.14835 (align); 1.96756 (contra)
2025-11-05 04:31:20,011: Loss(test): 1.65459 (total); 0.13396 (align); 1.96955 (contra)
2025-11-05 04:31:29,873: Finish train epoch 105 in 9.86 seconds.
2025-11-05 04:31:29,874: Loss(train): 1.13648 (total); 0.03164 (align); 1.95661 (contra)
2025-11-05 04:31:29,874: Loss(validation): 1.84827 (total); 0.17293 (align); 1.96722 (contra)
2025-11-05 04:31:29,874: Loss(test): 1.70402 (total); 0.14466 (align); 1.96144 (contra)
2025-11-05 04:31:39,602: Finish train epoch 106 in 9.73 seconds.
2025-11-05 04:31:39,603: Loss(train): 1.16714 (total); 0.03758 (align); 1.95846 (contra)
2025-11-05 04:31:39,603: Loss(validation): 1.84452 (total); 0.17122 (align); 1.97681 (contra)
2025-11-05 04:31:39,603: Loss(test): 1.59126 (total); 0.12039 (align); 1.97863 (contra)
2025-11-05 04:31:49,260: Finish train epoch 107 in 9.66 seconds.
2025-11-05 04:31:49,261: Loss(train): 1.14291 (total); 0.03275 (align); 1.95834 (contra)
2025-11-05 04:31:49,261: Loss(validation): 1.75883 (total); 0.15420 (align); 1.97563 (contra)
2025-11-05 04:31:49,261: Loss(test): 1.70840 (total); 0.14402 (align); 1.97665 (contra)
2025-11-05 04:31:58,848: Finish train epoch 108 in 9.59 seconds.
2025-11-05 04:31:58,848: Loss(train): 1.13891 (total); 0.03207 (align); 1.95716 (contra)
2025-11-05 04:31:58,849: Loss(validation): 1.79529 (total); 0.16175 (align); 1.97312 (contra)
2025-11-05 04:31:58,849: Loss(test): 1.65552 (total); 0.13317 (align); 1.97932 (contra)
2025-11-05 04:32:08,440: Finish train epoch 109 in 9.59 seconds.
2025-11-05 04:32:08,441: Loss(train): 1.11892 (total); 0.02795 (align); 1.95832 (contra)
2025-11-05 04:32:08,441: Loss(validation): 1.63913 (total); 0.13112 (align); 1.96709 (contra)
2025-11-05 04:32:08,441: Loss(test): 1.60726 (total); 0.12428 (align); 1.97170 (contra)
2025-11-05 04:32:08,543: New best model saved (epoch 109) with val_loss=1.639134
2025-11-05 04:32:18,189: Finish train epoch 110 in 9.65 seconds.
2025-11-05 04:32:18,189: Loss(train): 1.10847 (total); 0.02593 (align); 1.95768 (contra)
2025-11-05 04:32:18,190: Loss(validation): 1.84824 (total); 0.17033 (align); 1.99315 (contra)
2025-11-05 04:32:18,190: Loss(test): 1.80258 (total); 0.16099 (align); 1.99530 (contra)
2025-11-05 04:32:27,796: Finish train epoch 111 in 9.61 seconds.
2025-11-05 04:32:27,797: Loss(train): 1.11097 (total); 0.02635 (align); 1.95844 (contra)
2025-11-05 04:32:27,797: Loss(validation): 1.70433 (total); 0.14363 (align); 1.97234 (contra)
2025-11-05 04:32:27,798: Loss(test): 1.61340 (total); 0.12517 (align); 1.97510 (contra)
2025-11-05 04:32:37,570: Finish train epoch 112 in 9.77 seconds.
2025-11-05 04:32:37,571: Loss(train): 1.11571 (total); 0.02703 (align); 1.96114 (contra)
2025-11-05 04:32:37,571: Loss(validation): 1.65152 (total); 0.13369 (align); 1.96616 (contra)
2025-11-05 04:32:37,571: Loss(test): 1.65145 (total); 0.13349 (align); 1.96798 (contra)
2025-11-05 04:32:47,461: Finish train epoch 113 in 9.89 seconds.
2025-11-05 04:32:47,462: Loss(train): 1.10524 (total); 0.02551 (align); 1.95540 (contra)
2025-11-05 04:32:47,462: Loss(validation): 1.71423 (total); 0.14639 (align); 1.96460 (contra)
2025-11-05 04:32:47,463: Loss(test): 1.65931 (total); 0.13491 (align); 1.96955 (contra)
2025-11-05 04:32:57,264: Finish train epoch 114 in 9.80 seconds.
2025-11-05 04:32:57,265: Loss(train): 1.06042 (total); 0.01667 (align); 1.95411 (contra)
2025-11-05 04:32:57,265: Loss(validation): 1.65948 (total); 0.13547 (align); 1.96430 (contra)
2025-11-05 04:32:57,265: Loss(test): 1.61775 (total); 0.12656 (align); 1.96992 (contra)
2025-11-05 04:33:07,096: Finish train epoch 115 in 9.83 seconds.
2025-11-05 04:33:07,097: Loss(train): 1.07539 (total); 0.01959 (align); 1.95492 (contra)
2025-11-05 04:33:07,097: Loss(validation): 1.75594 (total); 0.15440 (align); 1.96789 (contra)
2025-11-05 04:33:07,097: Loss(test): 1.65639 (total); 0.13444 (align); 1.96842 (contra)
2025-11-05 04:33:16,873: Finish train epoch 116 in 9.78 seconds.
2025-11-05 04:33:16,874: Loss(train): 1.06419 (total); 0.01730 (align); 1.95540 (contra)
2025-11-05 04:33:16,874: Loss(validation): 1.74091 (total); 0.15061 (align); 1.97572 (contra)
2025-11-05 04:33:16,874: Loss(test): 1.70800 (total); 0.14381 (align); 1.97793 (contra)
2025-11-05 04:33:26,670: Finish train epoch 117 in 9.79 seconds.
2025-11-05 04:33:26,671: Loss(train): 1.06013 (total); 0.01668 (align); 1.95342 (contra)
2025-11-05 04:33:26,671: Loss(validation): 1.73015 (total); 0.14873 (align); 1.97306 (contra)
2025-11-05 04:33:26,671: Loss(test): 1.71937 (total); 0.14700 (align); 1.96871 (contra)
2025-11-05 04:33:36,495: Finish train epoch 118 in 9.82 seconds.
2025-11-05 04:33:36,496: Loss(train): 1.06686 (total); 0.01794 (align); 1.95436 (contra)
2025-11-05 04:33:36,496: Loss(validation): 1.83762 (total); 0.16989 (align); 1.97638 (contra)
2025-11-05 04:33:36,496: Loss(test): 1.66869 (total); 0.13543 (align); 1.98309 (contra)
2025-11-05 04:33:46,353: Finish train epoch 119 in 9.86 seconds.
2025-11-05 04:33:46,354: Loss(train): 1.09462 (total); 0.02320 (align); 1.95724 (contra)
2025-11-05 04:33:46,354: Loss(validation): 1.73247 (total); 0.15006 (align); 1.96430 (contra)
2025-11-05 04:33:46,354: Loss(test): 1.71829 (total); 0.14672 (align); 1.96938 (contra)
2025-11-05 04:33:56,231: Finish train epoch 120 in 9.88 seconds.
2025-11-05 04:33:56,232: Loss(train): 1.10705 (total); 0.02571 (align); 1.95701 (contra)
2025-11-05 04:33:56,232: Loss(validation): 1.76573 (total); 0.15649 (align); 1.96658 (contra)
2025-11-05 04:33:56,233: Loss(test): 1.63862 (total); 0.13116 (align); 1.96568 (contra)
2025-11-05 04:34:05,979: Finish train epoch 121 in 9.75 seconds.
2025-11-05 04:34:05,980: Loss(train): 1.08422 (total); 0.02149 (align); 1.95355 (contra)
2025-11-05 04:34:05,980: Loss(validation): 1.70957 (total); 0.14529 (align); 1.96618 (contra)
2025-11-05 04:34:05,980: Loss(test): 1.63821 (total); 0.13124 (align); 1.96402 (contra)
2025-11-05 04:34:15,619: Finish train epoch 122 in 9.64 seconds.
2025-11-05 04:34:15,620: Loss(train): 1.04503 (total); 0.01374 (align); 1.95262 (contra)
2025-11-05 04:34:15,620: Loss(validation): 1.65115 (total); 0.13343 (align); 1.96798 (contra)
2025-11-05 04:34:15,621: Loss(test): 1.63300 (total); 0.12998 (align); 1.96624 (contra)
2025-11-05 04:34:25,244: Finish train epoch 123 in 9.62 seconds.
2025-11-05 04:34:25,245: Loss(train): 1.07178 (total); 0.01889 (align); 1.95467 (contra)
2025-11-05 04:34:25,245: Loss(validation): 1.64044 (total); 0.13113 (align); 1.96961 (contra)
2025-11-05 04:34:25,245: Loss(test): 1.62790 (total); 0.12838 (align); 1.97201 (contra)
2025-11-05 04:34:34,911: Finish train epoch 124 in 9.67 seconds.
2025-11-05 04:34:34,912: Loss(train): 1.06863 (total); 0.01830 (align); 1.95431 (contra)
2025-11-05 04:34:34,912: Loss(validation): 1.61395 (total); 0.12612 (align); 1.96667 (contra)
2025-11-05 04:34:34,912: Loss(test): 1.61332 (total); 0.12626 (align); 1.96406 (contra)
2025-11-05 04:34:35,009: New best model saved (epoch 124) with val_loss=1.613948
2025-11-05 04:34:44,807: Finish train epoch 125 in 9.80 seconds.
2025-11-05 04:34:44,808: Loss(train): 1.07289 (total); 0.01911 (align); 1.95468 (contra)
2025-11-05 04:34:44,808: Loss(validation): 1.72190 (total); 0.14783 (align); 1.96552 (contra)
2025-11-05 04:34:44,808: Loss(test): 1.71327 (total); 0.14607 (align); 1.96583 (contra)
2025-11-05 04:34:54,664: Finish train epoch 126 in 9.86 seconds.
2025-11-05 04:34:54,665: Loss(train): 1.12314 (total); 0.02878 (align); 1.95844 (contra)
2025-11-05 04:34:54,665: Loss(validation): 1.75082 (total); 0.15308 (align); 1.97088 (contra)
2025-11-05 04:34:54,665: Loss(test): 1.68948 (total); 0.14097 (align); 1.96923 (contra)
2025-11-05 04:35:04,447: Finish train epoch 127 in 9.78 seconds.
2025-11-05 04:35:04,448: Loss(train): 1.11818 (total); 0.02792 (align); 1.95720 (contra)
2025-11-05 04:35:04,448: Loss(validation): 1.68992 (total); 0.14143 (align); 1.96552 (contra)
2025-11-05 04:35:04,448: Loss(test): 1.66069 (total); 0.13534 (align); 1.96799 (contra)
2025-11-05 04:35:14,253: Finish train epoch 128 in 9.80 seconds.
2025-11-05 04:35:14,254: Loss(train): 1.06801 (total); 0.01817 (align); 1.95432 (contra)
2025-11-05 04:35:14,254: Loss(validation): 1.75422 (total); 0.15397 (align); 1.96874 (contra)
2025-11-05 04:35:14,254: Loss(test): 1.71941 (total); 0.14660 (align); 1.97277 (contra)
2025-11-05 04:35:23,958: Finish train epoch 129 in 9.70 seconds.
2025-11-05 04:35:23,959: Loss(train): 1.07288 (total); 0.01916 (align); 1.95413 (contra)
2025-11-05 04:35:23,959: Loss(validation): 1.71383 (total); 0.14554 (align); 1.97223 (contra)
2025-11-05 04:35:23,959: Loss(test): 1.65102 (total); 0.13252 (align); 1.97683 (contra)
2025-11-05 04:35:33,741: Finish train epoch 130 in 9.78 seconds.
2025-11-05 04:35:33,742: Loss(train): 1.06037 (total); 0.01678 (align); 1.95295 (contra)
2025-11-05 04:35:33,742: Loss(validation): 1.72180 (total); 0.14782 (align); 1.96536 (contra)
2025-11-05 04:35:33,742: Loss(test): 1.60998 (total); 0.12545 (align); 1.96549 (contra)
2025-11-05 04:35:43,430: Finish train epoch 131 in 9.69 seconds.
2025-11-05 04:35:43,431: Loss(train): 1.04734 (total); 0.01409 (align); 1.95381 (contra)
2025-11-05 04:35:43,431: Loss(validation): 1.68792 (total); 0.14079 (align); 1.96790 (contra)
2025-11-05 04:35:43,431: Loss(test): 1.65279 (total); 0.13404 (align); 1.96519 (contra)
2025-11-05 04:35:53,149: Finish train epoch 132 in 9.72 seconds.
2025-11-05 04:35:53,150: Loss(train): 1.05999 (total); 0.01656 (align); 1.95433 (contra)
2025-11-05 04:35:53,150: Loss(validation): 1.66393 (total); 0.13660 (align); 1.96188 (contra)
2025-11-05 04:35:53,150: Loss(test): 1.62932 (total); 0.12970 (align); 1.96162 (contra)
2025-11-05 04:36:02,891: Finish train epoch 133 in 9.74 seconds.
2025-11-05 04:36:02,891: Loss(train): 1.19362 (total); 0.04249 (align); 1.96236 (contra)
2025-11-05 04:36:02,892: Loss(validation): 1.94055 (total); 0.18941 (align); 1.98704 (contra)
2025-11-05 04:36:02,892: Loss(test): 1.83919 (total); 0.16968 (align); 1.98159 (contra)
2025-11-05 04:36:12,633: Finish train epoch 134 in 9.74 seconds.
2025-11-05 04:36:12,634: Loss(train): 1.19024 (total); 0.04196 (align); 1.96082 (contra)
2025-11-05 04:36:12,634: Loss(validation): 1.75163 (total); 0.15261 (align); 1.97719 (contra)
2025-11-05 04:36:12,634: Loss(test): 1.64934 (total); 0.13212 (align); 1.97746 (contra)
2025-11-05 04:36:22,349: Finish train epoch 135 in 9.71 seconds.
2025-11-05 04:36:22,350: Loss(train): 1.06679 (total); 0.01800 (align); 1.95362 (contra)
2025-11-05 04:36:22,350: Loss(validation): 1.70971 (total); 0.14514 (align); 1.96806 (contra)
2025-11-05 04:36:22,350: Loss(test): 1.53874 (total); 0.11152 (align); 1.96226 (contra)
2025-11-05 04:36:32,081: Finish train epoch 136 in 9.73 seconds.
2025-11-05 04:36:32,082: Loss(train): 1.07321 (total); 0.01918 (align); 1.95458 (contra)
2025-11-05 04:36:32,082: Loss(validation): 1.63337 (total); 0.12908 (align); 1.97592 (contra)
2025-11-05 04:36:32,082: Loss(test): 1.56355 (total); 0.11567 (align); 1.97035 (contra)
2025-11-05 04:36:41,881: Finish train epoch 137 in 9.80 seconds.
2025-11-05 04:36:41,881: Loss(train): 1.05900 (total); 0.01651 (align); 1.95288 (contra)
2025-11-05 04:36:41,882: Loss(validation): 1.70003 (total); 0.14385 (align); 1.96155 (contra)
2025-11-05 04:36:41,882: Loss(test): 1.64838 (total); 0.13284 (align); 1.96840 (contra)
2025-11-05 04:36:51,798: Finish train epoch 138 in 9.92 seconds.
2025-11-05 04:36:51,798: Loss(train): 1.06395 (total); 0.01713 (align); 1.95660 (contra)
2025-11-05 04:36:51,799: Loss(validation): 1.68746 (total); 0.13867 (align); 1.98824 (contra)
2025-11-05 04:36:51,799: Loss(test): 1.64178 (total); 0.12900 (align); 1.99361 (contra)
2025-11-05 04:37:01,777: Finish train epoch 139 in 9.98 seconds.
2025-11-05 04:37:01,778: Loss(train): 1.07300 (total); 0.01896 (align); 1.95640 (contra)
2025-11-05 04:37:01,778: Loss(validation): 1.67921 (total); 0.13893 (align); 1.96908 (contra)
2025-11-05 04:37:01,778: Loss(test): 1.66284 (total); 0.13569 (align); 1.96880 (contra)
2025-11-05 04:37:11,630: Finish train epoch 140 in 9.85 seconds.
2025-11-05 04:37:11,631: Loss(train): 1.06713 (total); 0.01786 (align); 1.95565 (contra)
2025-11-05 04:37:11,631: Loss(validation): 1.66146 (total); 0.13575 (align); 1.96542 (contra)
2025-11-05 04:37:11,632: Loss(test): 1.54332 (total); 0.11184 (align); 1.96827 (contra)
2025-11-05 04:37:21,341: Finish train epoch 141 in 9.71 seconds.
2025-11-05 04:37:21,342: Loss(train): 1.04712 (total); 0.01405 (align); 1.95379 (contra)
2025-11-05 04:37:21,342: Loss(validation): 1.73947 (total); 0.15086 (align); 1.97032 (contra)
2025-11-05 04:37:21,343: Loss(test): 1.65049 (total); 0.13285 (align); 1.97251 (contra)
2025-11-05 04:37:31,010: Finish train epoch 142 in 9.67 seconds.
2025-11-05 04:37:31,011: Loss(train): 1.09866 (total); 0.02368 (align); 1.96047 (contra)
2025-11-05 04:37:31,012: Loss(validation): 1.73990 (total); 0.15098 (align); 1.96996 (contra)
2025-11-05 04:37:31,012: Loss(test): 1.62236 (total); 0.12730 (align); 1.97175 (contra)
2025-11-05 04:37:40,715: Finish train epoch 143 in 9.70 seconds.
2025-11-05 04:37:40,716: Loss(train): 1.14360 (total); 0.03294 (align); 1.95776 (contra)
2025-11-05 04:37:40,716: Loss(validation): 1.69326 (total); 0.14162 (align); 1.97038 (contra)
2025-11-05 04:37:40,716: Loss(test): 1.66780 (total); 0.13592 (align); 1.97636 (contra)
2025-11-05 04:37:50,492: Finish train epoch 144 in 9.78 seconds.
2025-11-05 04:37:50,493: Loss(train): 1.05486 (total); 0.01572 (align); 1.95254 (contra)
2025-11-05 04:37:50,493: Loss(validation): 1.67845 (total); 0.13954 (align); 1.96147 (contra)
2025-11-05 04:37:50,494: Loss(test): 1.62529 (total); 0.12784 (align); 1.97217 (contra)
2025-11-05 04:38:00,213: Finish train epoch 145 in 9.72 seconds.
2025-11-05 04:38:00,213: Loss(train): 1.04095 (total); 0.01305 (align); 1.95143 (contra)
2025-11-05 04:38:00,214: Loss(validation): 1.66777 (total); 0.13705 (align); 1.96509 (contra)
2025-11-05 04:38:00,214: Loss(test): 1.55796 (total); 0.11461 (align); 1.96980 (contra)
2025-11-05 04:38:09,934: Finish train epoch 146 in 9.72 seconds.
2025-11-05 04:38:09,935: Loss(train): 1.03519 (total); 0.01182 (align); 1.95218 (contra)
2025-11-05 04:38:09,935: Loss(validation): 1.75732 (total); 0.15416 (align); 1.97305 (contra)
2025-11-05 04:38:09,935: Loss(test): 1.58907 (total); 0.12064 (align); 1.97179 (contra)
2025-11-05 04:38:19,611: Finish train epoch 147 in 9.68 seconds.
2025-11-05 04:38:19,612: Loss(train): 1.10148 (total); 0.02440 (align); 1.95891 (contra)
2025-11-05 04:38:19,612: Loss(validation): 1.70736 (total); 0.14459 (align); 1.96883 (contra)
2025-11-05 04:38:19,613: Loss(test): 1.59940 (total); 0.12243 (align); 1.97444 (contra)
2025-11-05 04:38:29,300: Finish train epoch 148 in 9.69 seconds.
2025-11-05 04:38:29,301: Loss(train): 1.04261 (total); 0.01343 (align); 1.95091 (contra)
2025-11-05 04:38:29,301: Loss(validation): 1.72381 (total); 0.14889 (align); 1.95870 (contra)
2025-11-05 04:38:29,302: Loss(test): 1.60589 (total); 0.12492 (align); 1.96263 (contra)
2025-11-05 04:38:39,039: Finish train epoch 149 in 9.74 seconds.
2025-11-05 04:38:39,040: Loss(train): 1.03120 (total); 0.01119 (align); 1.95047 (contra)
2025-11-05 04:38:39,040: Loss(validation): 1.62943 (total); 0.12974 (align); 1.96141 (contra)
2025-11-05 04:38:39,040: Loss(test): 1.53546 (total); 0.11025 (align); 1.96843 (contra)
2025-11-05 04:38:39,443: Saved test embeddings to /mnt/afs/250010218/multi-level-Chinese-decoding/train/duin/../../summaries/2025-11-05/4/train/ckpt/test_embeddings_epoch_150.npy
2025-11-05 04:38:49,129: Finish train epoch 150 in 9.69 seconds.
2025-11-05 04:38:49,130: Loss(train): 1.03375 (total); 0.01139 (align); 1.95358 (contra)
2025-11-05 04:38:49,130: Loss(validation): 1.72811 (total); 0.14856 (align); 1.97059 (contra)
2025-11-05 04:38:49,130: Loss(test): 1.58915 (total); 0.12034 (align); 1.97490 (contra)
2025-11-05 04:38:58,895: Finish train epoch 151 in 9.76 seconds.
2025-11-05 04:38:58,896: Loss(train): 1.06263 (total); 0.01721 (align); 1.95318 (contra)
2025-11-05 04:38:58,896: Loss(validation): 1.83412 (total); 0.16967 (align); 1.97153 (contra)
2025-11-05 04:38:58,896: Loss(test): 1.70005 (total); 0.14247 (align); 1.97545 (contra)
2025-11-05 04:39:08,651: Finish train epoch 152 in 9.75 seconds.
2025-11-05 04:39:08,652: Loss(train): 1.08869 (total); 0.02219 (align); 1.95547 (contra)
2025-11-05 04:39:08,652: Loss(validation): 1.84611 (total); 0.17173 (align); 1.97488 (contra)
2025-11-05 04:39:08,652: Loss(test): 1.79641 (total); 0.16162 (align); 1.97659 (contra)
2025-11-05 04:39:18,365: Finish train epoch 153 in 9.71 seconds.
2025-11-05 04:39:18,366: Loss(train): 1.07539 (total); 0.01964 (align); 1.95435 (contra)
2025-11-05 04:39:18,366: Loss(validation): 1.85872 (total); 0.17518 (align); 1.96566 (contra)
2025-11-05 04:39:18,366: Loss(test): 1.65803 (total); 0.13452 (align); 1.97082 (contra)
2025-11-05 04:39:28,119: Finish train epoch 154 in 9.75 seconds.
2025-11-05 04:39:28,119: Loss(train): 1.05444 (total); 0.01556 (align); 1.95331 (contra)
2025-11-05 04:39:28,119: Loss(validation): 1.84622 (total); 0.17282 (align); 1.96420 (contra)
2025-11-05 04:39:28,120: Loss(test): 1.66827 (total); 0.13686 (align); 1.96791 (contra)
2025-11-05 04:39:37,827: Finish train epoch 155 in 9.71 seconds.
2025-11-05 04:39:37,828: Loss(train): 1.02743 (total); 0.01018 (align); 1.95303 (contra)
2025-11-05 04:39:37,828: Loss(validation): 1.66003 (total); 0.13557 (align); 1.96437 (contra)
2025-11-05 04:39:37,828: Loss(test): 1.62504 (total); 0.12860 (align); 1.96410 (contra)
2025-11-05 04:39:47,583: Finish train epoch 156 in 9.75 seconds.
2025-11-05 04:39:47,584: Loss(train): 1.03163 (total); 0.01110 (align); 1.95227 (contra)
2025-11-05 04:39:47,585: Loss(validation): 1.69058 (total); 0.14175 (align); 1.96364 (contra)
2025-11-05 04:39:47,585: Loss(test): 1.56101 (total); 0.11600 (align); 1.96198 (contra)
2025-11-05 04:39:57,325: Finish train epoch 157 in 9.74 seconds.
2025-11-05 04:39:57,326: Loss(train): 1.02320 (total); 0.00953 (align); 1.95108 (contra)
2025-11-05 04:39:57,326: Loss(validation): 1.73088 (total); 0.15009 (align); 1.96083 (contra)
2025-11-05 04:39:57,327: Loss(test): 1.57840 (total); 0.11934 (align); 1.96344 (contra)
2025-11-05 04:40:07,041: Finish train epoch 158 in 9.71 seconds.
2025-11-05 04:40:07,042: Loss(train): 1.03047 (total); 0.01106 (align); 1.95037 (contra)
2025-11-05 04:40:07,042: Loss(validation): 1.63973 (total); 0.13142 (align); 1.96523 (contra)
2025-11-05 04:40:07,043: Loss(test): 1.58891 (total); 0.12095 (align); 1.96834 (contra)
2025-11-05 04:40:16,805: Finish train epoch 159 in 9.76 seconds.
2025-11-05 04:40:16,806: Loss(train): 1.02807 (total); 0.01035 (align); 1.95260 (contra)
2025-11-05 04:40:16,806: Loss(validation): 1.67206 (total); 0.13839 (align); 1.96023 (contra)
2025-11-05 04:40:16,807: Loss(test): 1.61388 (total); 0.12599 (align); 1.96786 (contra)
2025-11-05 04:40:26,517: Finish train epoch 160 in 9.71 seconds.
2025-11-05 04:40:26,518: Loss(train): 1.02609 (total); 0.01015 (align); 1.95072 (contra)
2025-11-05 04:40:26,518: Loss(validation): 1.70330 (total); 0.14427 (align); 1.96386 (contra)
2025-11-05 04:40:26,518: Loss(test): 1.65931 (total); 0.13547 (align); 1.96393 (contra)
2025-11-05 04:40:36,218: Finish train epoch 161 in 9.70 seconds.
2025-11-05 04:40:36,218: Loss(train): 1.01928 (total); 0.00879 (align); 1.95062 (contra)
2025-11-05 04:40:36,219: Loss(validation): 1.73533 (total); 0.15140 (align); 1.95667 (contra)
2025-11-05 04:40:36,219: Loss(test): 1.63143 (total); 0.13021 (align); 1.96078 (contra)
2025-11-05 04:40:45,913: Finish train epoch 162 in 9.69 seconds.
2025-11-05 04:40:45,914: Loss(train): 1.02205 (total); 0.00921 (align); 1.95204 (contra)
2025-11-05 04:40:45,914: Loss(validation): 1.80504 (total); 0.16476 (align); 1.96245 (contra)
2025-11-05 04:40:45,914: Loss(test): 1.71864 (total); 0.14780 (align); 1.95932 (contra)
2025-11-05 04:40:55,609: Finish train epoch 163 in 9.69 seconds.
2025-11-05 04:40:55,610: Loss(train): 1.21074 (total); 0.04545 (align); 1.96692 (contra)
2025-11-05 04:40:55,610: Loss(validation): 1.90874 (total); 0.18221 (align); 1.99538 (contra)
2025-11-05 04:40:55,610: Loss(test): 1.91896 (total); 0.18384 (align); 1.99955 (contra)
2025-11-05 04:41:05,359: Finish train epoch 164 in 9.75 seconds.
2025-11-05 04:41:05,359: Loss(train): 1.20104 (total); 0.04379 (align); 1.96421 (contra)
2025-11-05 04:41:05,360: Loss(validation): 1.77645 (total); 0.15877 (align); 1.96524 (contra)
2025-11-05 04:41:05,360: Loss(test): 1.75535 (total); 0.15429 (align); 1.96780 (contra)
2025-11-05 04:41:15,184: Finish train epoch 165 in 9.82 seconds.
2025-11-05 04:41:15,185: Loss(train): 1.09624 (total); 0.02364 (align); 1.95610 (contra)
2025-11-05 04:41:15,185: Loss(validation): 1.72214 (total); 0.14797 (align); 1.96457 (contra)
2025-11-05 04:41:15,186: Loss(test): 1.58992 (total); 0.12150 (align); 1.96489 (contra)
2025-11-05 04:41:24,844: Finish train epoch 166 in 9.66 seconds.
2025-11-05 04:41:24,844: Loss(train): 1.07203 (total); 0.01885 (align); 1.95552 (contra)
2025-11-05 04:41:24,845: Loss(validation): 1.73641 (total); 0.15059 (align); 1.96691 (contra)
2025-11-05 04:41:24,845: Loss(test): 1.58872 (total); 0.12097 (align); 1.96778 (contra)
2025-11-05 04:41:34,636: Finish train epoch 167 in 9.79 seconds.
2025-11-05 04:41:34,637: Loss(train): 1.04017 (total); 0.01285 (align); 1.95178 (contra)
2025-11-05 04:41:34,637: Loss(validation): 1.62840 (total); 0.12838 (align); 1.97300 (contra)
2025-11-05 04:41:34,637: Loss(test): 1.57759 (total); 0.11888 (align); 1.96641 (contra)
2025-11-05 04:41:44,358: Finish train epoch 168 in 9.72 seconds.
2025-11-05 04:41:44,358: Loss(train): 1.01131 (total); 0.00731 (align); 1.94949 (contra)
2025-11-05 04:41:44,359: Loss(validation): 1.52982 (total); 0.10985 (align); 1.96120 (contra)
2025-11-05 04:41:44,359: Loss(test): 1.51395 (total); 0.10662 (align); 1.96168 (contra)
2025-11-05 04:41:44,469: New best model saved (epoch 168) with val_loss=1.529824
2025-11-05 04:41:54,361: Finish train epoch 169 in 9.89 seconds.
2025-11-05 04:41:54,362: Loss(train): 1.01575 (total); 0.00814 (align); 1.95006 (contra)
2025-11-05 04:41:54,362: Loss(validation): 1.56923 (total); 0.11732 (align); 1.96525 (contra)
2025-11-05 04:41:54,362: Loss(test): 1.57051 (total); 0.11806 (align); 1.96044 (contra)
2025-11-05 04:42:04,192: Finish train epoch 170 in 9.83 seconds.
2025-11-05 04:42:04,193: Loss(train): 1.02401 (total); 0.00977 (align); 1.95034 (contra)
2025-11-05 04:42:04,193: Loss(validation): 1.67502 (total); 0.13860 (align); 1.96400 (contra)
2025-11-05 04:42:04,193: Loss(test): 1.57841 (total); 0.11941 (align); 1.96267 (contra)
2025-11-05 04:42:13,923: Finish train epoch 171 in 9.73 seconds.
2025-11-05 04:42:13,924: Loss(train): 1.09409 (total); 0.02325 (align); 1.95570 (contra)
2025-11-05 04:42:13,924: Loss(validation): 1.81983 (total); 0.16585 (align); 1.98120 (contra)
2025-11-05 04:42:13,924: Loss(test): 1.83055 (total); 0.16844 (align); 1.97670 (contra)
2025-11-05 04:42:23,668: Finish train epoch 172 in 9.74 seconds.
2025-11-05 04:42:23,668: Loss(train): 1.06448 (total); 0.01743 (align); 1.95464 (contra)
2025-11-05 04:42:23,669: Loss(validation): 1.67338 (total); 0.13851 (align); 1.96167 (contra)
2025-11-05 04:42:23,669: Loss(test): 1.64219 (total); 0.13165 (align); 1.96789 (contra)
2025-11-05 04:42:33,592: Finish train epoch 173 in 9.92 seconds.
2025-11-05 04:42:33,592: Loss(train): 1.04222 (total); 0.01341 (align); 1.95039 (contra)
2025-11-05 04:42:33,592: Loss(validation): 1.63007 (total); 0.12948 (align); 1.96537 (contra)
2025-11-05 04:42:33,593: Loss(test): 1.63548 (total); 0.13034 (align); 1.96757 (contra)
2025-11-05 04:42:43,392: Finish train epoch 174 in 9.80 seconds.
2025-11-05 04:42:43,392: Loss(train): 1.03815 (total); 0.01258 (align); 1.95054 (contra)
2025-11-05 04:42:43,393: Loss(validation): 1.58456 (total); 0.12072 (align); 1.96190 (contra)
2025-11-05 04:42:43,393: Loss(test): 1.63197 (total); 0.12977 (align); 1.96625 (contra)
2025-11-05 04:42:53,178: Finish train epoch 175 in 9.79 seconds.
2025-11-05 04:42:53,179: Loss(train): 1.04258 (total); 0.01353 (align); 1.94987 (contra)
2025-11-05 04:42:53,179: Loss(validation): 1.61974 (total); 0.12822 (align); 1.95733 (contra)
2025-11-05 04:42:53,180: Loss(test): 1.57980 (total); 0.11971 (align); 1.96255 (contra)
2025-11-05 04:43:02,822: Finish train epoch 176 in 9.64 seconds.
2025-11-05 04:43:02,823: Loss(train): 1.02937 (total); 0.01082 (align); 1.95057 (contra)
2025-11-05 04:43:02,823: Loss(validation): 1.82247 (total); 0.16835 (align); 1.96142 (contra)
2025-11-05 04:43:02,823: Loss(test): 1.68071 (total); 0.14002 (align); 1.96119 (contra)
2025-11-05 04:43:12,445: Finish train epoch 177 in 9.62 seconds.
2025-11-05 04:43:12,446: Loss(train): 1.04374 (total); 0.01358 (align); 1.95168 (contra)
2025-11-05 04:43:12,446: Loss(validation): 1.71208 (total); 0.14633 (align); 1.96090 (contra)
2025-11-05 04:43:12,446: Loss(test): 1.60901 (total); 0.12507 (align); 1.96731 (contra)
2025-11-05 04:43:22,079: Finish train epoch 178 in 9.63 seconds.
2025-11-05 04:43:22,080: Loss(train): 1.01294 (total); 0.00773 (align); 1.94856 (contra)
2025-11-05 04:43:22,080: Loss(validation): 1.67484 (total); 0.13923 (align); 1.95732 (contra)
2025-11-05 04:43:22,080: Loss(test): 1.55335 (total); 0.11452 (align); 1.96150 (contra)
2025-11-05 04:43:31,850: Finish train epoch 179 in 9.77 seconds.
2025-11-05 04:43:31,851: Loss(train): 1.01314 (total); 0.00754 (align); 1.95090 (contra)
2025-11-05 04:43:31,852: Loss(validation): 1.61134 (total); 0.12605 (align); 1.96218 (contra)
2025-11-05 04:43:31,852: Loss(test): 1.62132 (total); 0.12770 (align); 1.96567 (contra)
2025-11-05 04:43:41,490: Finish train epoch 180 in 9.64 seconds.
2025-11-05 04:43:41,491: Loss(train): 1.01156 (total); 0.00734 (align); 1.94974 (contra)
2025-11-05 04:43:41,491: Loss(validation): 1.61598 (total); 0.12715 (align); 1.96049 (contra)
2025-11-05 04:43:41,491: Loss(test): 1.61900 (total); 0.12768 (align); 1.96124 (contra)
2025-11-05 04:43:51,106: Finish train epoch 181 in 9.61 seconds.
2025-11-05 04:43:51,107: Loss(train): 1.03611 (total); 0.01209 (align); 1.95136 (contra)
2025-11-05 04:43:51,107: Loss(validation): 1.63507 (total); 0.13082 (align); 1.96192 (contra)
2025-11-05 04:43:51,107: Loss(test): 1.69912 (total); 0.14291 (align); 1.96912 (contra)
2025-11-05 04:44:00,712: Finish train epoch 182 in 9.60 seconds.
2025-11-05 04:44:00,713: Loss(train): 0.99813 (total); 0.00489 (align); 1.94735 (contra)
2025-11-05 04:44:00,713: Loss(validation): 1.63393 (total); 0.13098 (align); 1.95803 (contra)
2025-11-05 04:44:00,714: Loss(test): 1.60084 (total); 0.12364 (align); 1.96524 (contra)
2025-11-05 04:44:10,417: Finish train epoch 183 in 9.70 seconds.
2025-11-05 04:44:10,418: Loss(train): 1.00863 (total); 0.00686 (align); 1.94868 (contra)
2025-11-05 04:44:10,418: Loss(validation): 1.68049 (total); 0.13971 (align); 1.96388 (contra)
2025-11-05 04:44:10,419: Loss(test): 1.63933 (total); 0.13107 (align); 1.96798 (contra)
2025-11-05 04:44:20,067: Finish train epoch 184 in 9.65 seconds.
2025-11-05 04:44:20,068: Loss(train): 1.01089 (total); 0.00724 (align); 1.94940 (contra)
2025-11-05 04:44:20,068: Loss(validation): 1.59089 (total); 0.12260 (align); 1.95578 (contra)
2025-11-05 04:44:20,068: Loss(test): 1.59899 (total); 0.12331 (align); 1.96485 (contra)
2025-11-05 04:44:29,759: Finish train epoch 185 in 9.69 seconds.
2025-11-05 04:44:29,760: Loss(train): 0.98749 (total); 0.00274 (align); 1.94759 (contra)
2025-11-05 04:44:29,761: Loss(validation): 1.60681 (total); 0.12563 (align); 1.95729 (contra)
2025-11-05 04:44:29,761: Loss(test): 1.57348 (total); 0.11863 (align); 1.96069 (contra)
2025-11-05 04:44:39,380: Finish train epoch 186 in 9.62 seconds.
2025-11-05 04:44:39,381: Loss(train): 1.05421 (total); 0.01543 (align); 1.95409 (contra)
2025-11-05 04:44:39,381: Loss(validation): 1.79349 (total); 0.16005 (align); 1.98643 (contra)
2025-11-05 04:44:39,382: Loss(test): 1.76184 (total); 0.15284 (align); 1.99526 (contra)
2025-11-05 04:44:48,956: Finish train epoch 187 in 9.57 seconds.
2025-11-05 04:44:48,957: Loss(train): 1.04222 (total); 0.01317 (align); 1.95271 (contra)
2025-11-05 04:44:48,958: Loss(validation): 1.69383 (total); 0.14177 (align); 1.96999 (contra)
2025-11-05 04:44:48,958: Loss(test): 1.59419 (total); 0.12109 (align); 1.97754 (contra)
2025-11-05 04:44:58,578: Finish train epoch 188 in 9.62 seconds.
2025-11-05 04:44:58,578: Loss(train): 1.02408 (total); 0.00980 (align); 1.95018 (contra)
2025-11-05 04:44:58,578: Loss(validation): 1.73638 (total); 0.15143 (align); 1.95848 (contra)
2025-11-05 04:44:58,578: Loss(test): 1.68125 (total); 0.13953 (align); 1.96722 (contra)
2025-11-05 04:45:08,204: Finish train epoch 189 in 9.63 seconds.
2025-11-05 04:45:08,205: Loss(train): 1.02573 (total); 0.01016 (align); 1.94988 (contra)
2025-11-05 04:45:08,205: Loss(validation): 1.66715 (total); 0.13723 (align); 1.96197 (contra)
2025-11-05 04:45:08,205: Loss(test): 1.64448 (total); 0.13175 (align); 1.97150 (contra)
2025-11-05 04:45:17,805: Finish train epoch 190 in 9.60 seconds.
2025-11-05 04:45:17,806: Loss(train): 1.00634 (total); 0.00640 (align); 1.94870 (contra)
2025-11-05 04:45:17,806: Loss(validation): 1.63672 (total); 0.13125 (align); 1.96093 (contra)
2025-11-05 04:45:17,806: Loss(test): 1.58244 (total); 0.11963 (align); 1.96856 (contra)
2025-11-05 04:45:27,399: Finish train epoch 191 in 9.59 seconds.
2025-11-05 04:45:27,400: Loss(train): 1.00319 (total); 0.00579 (align); 1.94848 (contra)
2025-11-05 04:45:27,400: Loss(validation): 1.65153 (total); 0.13410 (align); 1.96206 (contra)
2025-11-05 04:45:27,400: Loss(test): 1.60161 (total); 0.12374 (align); 1.96578 (contra)
2025-11-05 04:45:36,974: Finish train epoch 192 in 9.57 seconds.
2025-11-05 04:45:36,975: Loss(train): 0.99829 (total); 0.00493 (align); 1.94726 (contra)
2025-11-05 04:45:36,975: Loss(validation): 1.62445 (total); 0.12848 (align); 1.96410 (contra)
2025-11-05 04:45:36,976: Loss(test): 1.61214 (total); 0.12512 (align); 1.97306 (contra)
2025-11-05 04:45:46,599: Finish train epoch 193 in 9.62 seconds.
2025-11-05 04:45:46,600: Loss(train): 1.00450 (total); 0.00608 (align); 1.94822 (contra)
2025-11-05 04:45:46,601: Loss(validation): 1.63169 (total); 0.12982 (align); 1.96517 (contra)
2025-11-05 04:45:46,601: Loss(test): 1.58091 (total); 0.11977 (align); 1.96407 (contra)
2025-11-05 04:45:56,353: Finish train epoch 194 in 9.75 seconds.
2025-11-05 04:45:56,354: Loss(train): 0.99555 (total); 0.00424 (align); 1.94866 (contra)
2025-11-05 04:45:56,354: Loss(validation): 1.63801 (total); 0.13131 (align); 1.96291 (contra)
2025-11-05 04:45:56,354: Loss(test): 1.58135 (total); 0.11985 (align); 1.96424 (contra)
2025-11-05 04:46:06,140: Finish train epoch 195 in 9.79 seconds.
2025-11-05 04:46:06,141: Loss(train): 0.98694 (total); 0.00272 (align); 1.94665 (contra)
2025-11-05 04:46:06,142: Loss(validation): 1.58555 (total); 0.12144 (align); 1.95668 (contra)
2025-11-05 04:46:06,142: Loss(test): 1.60980 (total); 0.12571 (align); 1.96247 (contra)
2025-11-05 04:46:15,954: Finish train epoch 196 in 9.81 seconds.
2025-11-05 04:46:15,955: Loss(train): 0.99578 (total); 0.00431 (align); 1.94842 (contra)
2025-11-05 04:46:15,955: Loss(validation): 1.60066 (total); 0.12336 (align); 1.96771 (contra)
2025-11-05 04:46:15,955: Loss(test): 1.60198 (total); 0.12316 (align); 1.97239 (contra)
2025-11-05 04:46:25,720: Finish train epoch 197 in 9.76 seconds.
2025-11-05 04:46:25,721: Loss(train): 1.00289 (total); 0.00563 (align); 1.94946 (contra)
2025-11-05 04:46:25,721: Loss(validation): 1.57044 (total); 0.11756 (align); 1.96532 (contra)
2025-11-05 04:46:25,721: Loss(test): 1.52430 (total); 0.10824 (align); 1.96623 (contra)
2025-11-05 04:46:35,593: Finish train epoch 198 in 9.87 seconds.
2025-11-05 04:46:35,594: Loss(train): 0.99533 (total); 0.00422 (align); 1.94846 (contra)
2025-11-05 04:46:35,594: Loss(validation): 1.61899 (total); 0.12701 (align); 1.96785 (contra)
2025-11-05 04:46:35,594: Loss(test): 1.63628 (total); 0.13028 (align); 1.96974 (contra)
2025-11-05 04:46:45,489: Finish train epoch 199 in 9.89 seconds.
2025-11-05 04:46:45,490: Loss(train): 1.00056 (total); 0.00536 (align); 1.94755 (contra)
2025-11-05 04:46:45,491: Loss(validation): 1.64547 (total); 0.13362 (align); 1.95474 (contra)
2025-11-05 04:46:45,491: Loss(test): 1.53840 (total); 0.11124 (align); 1.96439 (contra)
2025-11-05 04:46:45,908: Saved test embeddings to /mnt/afs/250010218/multi-level-Chinese-decoding/train/duin/../../summaries/2025-11-05/4/train/ckpt/test_embeddings_epoch_200.npy
2025-11-05 04:46:55,737: Finish train epoch 200 in 9.83 seconds.
2025-11-05 04:46:55,738: Loss(train): 0.99237 (total); 0.00372 (align); 1.94752 (contra)
2025-11-05 04:46:55,738: Loss(validation): 1.64162 (total); 0.13194 (align); 1.96383 (contra)
2025-11-05 04:46:55,738: Loss(test): 1.60846 (total); 0.12548 (align); 1.96218 (contra)
2025-11-05 04:47:05,741: Finish train epoch 201 in 10.00 seconds.
2025-11-05 04:47:05,742: Loss(train): 0.99425 (total); 0.00415 (align); 1.94694 (contra)
2025-11-05 04:47:05,742: Loss(validation): 1.59571 (total); 0.12307 (align); 1.96075 (contra)
2025-11-05 04:47:05,742: Loss(test): 1.55793 (total); 0.11521 (align); 1.96376 (contra)
2025-11-05 04:47:15,651: Finish train epoch 202 in 9.91 seconds.
2025-11-05 04:47:15,651: Loss(train): 0.98685 (total); 0.00270 (align); 1.94672 (contra)
2025-11-05 04:47:15,652: Loss(validation): 1.64435 (total); 0.13304 (align); 1.95826 (contra)
2025-11-05 04:47:15,652: Loss(test): 1.54532 (total); 0.11338 (align); 1.95685 (contra)
2025-11-05 04:47:25,376: Finish train epoch 203 in 9.72 seconds.
2025-11-05 04:47:25,377: Loss(train): 0.98517 (total); 0.00236 (align); 1.94677 (contra)
2025-11-05 04:47:25,377: Loss(validation): 1.67101 (total); 0.13843 (align); 1.95767 (contra)
2025-11-05 04:47:25,377: Loss(test): 1.55912 (total); 0.11603 (align); 1.95788 (contra)
2025-11-05 04:47:35,069: Finish train epoch 204 in 9.69 seconds.
2025-11-05 04:47:35,069: Loss(train): 0.98928 (total); 0.00321 (align); 1.94648 (contra)
2025-11-05 04:47:35,070: Loss(validation): 1.64210 (total); 0.13252 (align); 1.95901 (contra)
2025-11-05 04:47:35,070: Loss(test): 1.54986 (total); 0.11383 (align); 1.96146 (contra)
2025-11-05 04:47:44,723: Finish train epoch 205 in 9.65 seconds.
2025-11-05 04:47:44,724: Loss(train): 0.98672 (total); 0.00256 (align); 1.94785 (contra)
2025-11-05 04:47:44,724: Loss(validation): 1.63617 (total); 0.13151 (align); 1.95730 (contra)
2025-11-05 04:47:44,724: Loss(test): 1.59050 (total); 0.12216 (align); 1.95941 (contra)
2025-11-05 04:47:54,404: Finish train epoch 206 in 9.68 seconds.
2025-11-05 04:47:54,405: Loss(train): 0.98368 (total); 0.00218 (align); 1.94560 (contra)
2025-11-05 04:47:54,405: Loss(validation): 1.62515 (total); 0.12890 (align); 1.96133 (contra)
2025-11-05 04:47:54,405: Loss(test): 1.60542 (total); 0.12469 (align); 1.96394 (contra)
2025-11-05 04:48:04,103: Finish train epoch 207 in 9.70 seconds.
2025-11-05 04:48:04,103: Loss(train): 1.04840 (total); 0.01416 (align); 1.95519 (contra)
2025-11-05 04:48:04,103: Loss(validation): 1.68905 (total); 0.14113 (align); 1.96680 (contra)
2025-11-05 04:48:04,104: Loss(test): 1.58343 (total); 0.12003 (align); 1.96660 (contra)
2025-11-05 04:48:13,847: Finish train epoch 208 in 9.74 seconds.
2025-11-05 04:48:13,848: Loss(train): 1.00477 (total); 0.00607 (align); 1.94881 (contra)
2025-11-05 04:48:13,848: Loss(validation): 1.62427 (total); 0.12866 (align); 1.96195 (contra)
2025-11-05 04:48:13,848: Loss(test): 1.51329 (total); 0.10620 (align); 1.96458 (contra)
2025-11-05 04:48:23,607: Finish train epoch 209 in 9.76 seconds.
2025-11-05 04:48:23,608: Loss(train): 0.99046 (total); 0.00335 (align); 1.94745 (contra)
2025-11-05 04:48:23,608: Loss(validation): 1.70672 (total); 0.14519 (align); 1.96154 (contra)
2025-11-05 04:48:23,608: Loss(test): 1.54612 (total); 0.11274 (align); 1.96482 (contra)
2025-11-05 04:48:33,302: Finish train epoch 210 in 9.69 seconds.
2025-11-05 04:48:33,303: Loss(train): 0.99543 (total); 0.00427 (align); 1.94820 (contra)
2025-11-05 04:48:33,303: Loss(validation): 1.60306 (total); 0.12441 (align); 1.96206 (contra)
2025-11-05 04:48:33,303: Loss(test): 1.54236 (total); 0.11239 (align); 1.96083 (contra)
2025-11-05 04:48:43,054: Finish train epoch 211 in 9.75 seconds.
2025-11-05 04:48:43,055: Loss(train): 0.99280 (total); 0.00380 (align); 1.94763 (contra)
2025-11-05 04:48:43,055: Loss(validation): 1.66130 (total); 0.13672 (align); 1.95536 (contra)
2025-11-05 04:48:43,056: Loss(test): 1.52980 (total); 0.10996 (align); 1.95997 (contra)
2025-11-05 04:48:52,753: Finish train epoch 212 in 9.70 seconds.
2025-11-05 04:48:52,754: Loss(train): 0.98729 (total); 0.00270 (align); 1.94758 (contra)
2025-11-05 04:48:52,754: Loss(validation): 1.61049 (total); 0.12599 (align); 1.96106 (contra)
2025-11-05 04:48:52,754: Loss(test): 1.52170 (total); 0.10794 (align); 1.96395 (contra)
2025-11-05 04:49:02,506: Finish train epoch 213 in 9.75 seconds.
2025-11-05 04:49:02,507: Loss(train): 0.98871 (total); 0.00286 (align); 1.94884 (contra)
2025-11-05 04:49:02,507: Loss(validation): 1.64052 (total); 0.13235 (align); 1.95752 (contra)
2025-11-05 04:49:02,507: Loss(test): 1.52540 (total); 0.10879 (align); 1.96294 (contra)
2025-11-05 04:49:12,286: Finish train epoch 214 in 9.78 seconds.
2025-11-05 04:49:12,287: Loss(train): 0.99897 (total); 0.00498 (align); 1.94813 (contra)
2025-11-05 04:49:12,287: Loss(validation): 1.63635 (total); 0.13121 (align); 1.96057 (contra)
2025-11-05 04:49:12,287: Loss(test): 1.52703 (total); 0.10946 (align); 1.95949 (contra)
2025-11-05 04:49:21,985: Finish train epoch 215 in 9.70 seconds.
2025-11-05 04:49:21,986: Loss(train): 0.99366 (total); 0.00406 (align); 1.94674 (contra)
2025-11-05 04:49:21,986: Loss(validation): 1.65957 (total); 0.13604 (align); 1.95875 (contra)
2025-11-05 04:49:21,986: Loss(test): 1.52043 (total); 0.10805 (align); 1.96041 (contra)
2025-11-05 04:49:31,719: Finish train epoch 216 in 9.73 seconds.
2025-11-05 04:49:31,720: Loss(train): 0.98984 (total); 0.00326 (align); 1.94708 (contra)
2025-11-05 04:49:31,721: Loss(validation): 1.70119 (total); 0.14416 (align); 1.96083 (contra)
2025-11-05 04:49:31,721: Loss(test): 1.54049 (total); 0.11180 (align); 1.96304 (contra)
2025-11-05 04:49:41,435: Finish train epoch 217 in 9.71 seconds.
2025-11-05 04:49:41,436: Loss(train): 0.99081 (total); 0.00344 (align); 1.94725 (contra)
2025-11-05 04:49:41,436: Loss(validation): 1.67465 (total); 0.13908 (align); 1.95845 (contra)
2025-11-05 04:49:41,436: Loss(test): 1.52562 (total); 0.10856 (align); 1.96565 (contra)
2025-11-05 04:49:51,068: Finish train epoch 218 in 9.63 seconds.
2025-11-05 04:49:51,069: Loss(train): 0.98441 (total); 0.00213 (align); 1.94749 (contra)
2025-11-05 04:49:51,069: Loss(validation): 1.67644 (total); 0.13896 (align); 1.96325 (contra)
2025-11-05 04:49:51,069: Loss(test): 1.52695 (total); 0.10896 (align); 1.96432 (contra)
2025-11-05 04:50:00,935: Finish train epoch 219 in 9.87 seconds.
2025-11-05 04:50:00,936: Loss(train): 0.98729 (total); 0.00275 (align); 1.94712 (contra)
2025-11-05 04:50:00,936: Loss(validation): 1.66736 (total); 0.13770 (align); 1.95774 (contra)
2025-11-05 04:50:00,936: Loss(test): 1.51223 (total); 0.10626 (align); 1.96188 (contra)
2025-11-05 04:50:10,555: Finish train epoch 220 in 9.62 seconds.
2025-11-05 04:50:10,556: Loss(train): 1.01347 (total); 0.00772 (align); 1.94974 (contra)
2025-11-05 04:50:10,556: Loss(validation): 1.67969 (total); 0.13965 (align); 1.96287 (contra)
2025-11-05 04:50:10,556: Loss(test): 1.60733 (total); 0.12456 (align); 1.96909 (contra)
2025-11-05 04:50:20,237: Finish train epoch 221 in 9.68 seconds.
2025-11-05 04:50:20,238: Loss(train): 1.02199 (total); 0.00943 (align); 1.94972 (contra)
2025-11-05 04:50:20,238: Loss(validation): 1.69696 (total); 0.14303 (align); 1.96365 (contra)
2025-11-05 04:50:20,238: Loss(test): 1.65074 (total); 0.13355 (align); 1.96597 (contra)
2025-11-05 04:50:29,958: Finish train epoch 222 in 9.72 seconds.
2025-11-05 04:50:29,959: Loss(train): 1.02985 (total); 0.01092 (align); 1.95046 (contra)
2025-11-05 04:50:29,959: Loss(validation): 1.77464 (total); 0.15879 (align); 1.96138 (contra)
2025-11-05 04:50:29,959: Loss(test): 1.63608 (total); 0.13069 (align); 1.96527 (contra)
2025-11-05 04:50:39,603: Finish train epoch 223 in 9.64 seconds.
2025-11-05 04:50:39,604: Loss(train): 1.02153 (total); 0.00921 (align); 1.95097 (contra)
2025-11-05 04:50:39,604: Loss(validation): 1.67914 (total); 0.13963 (align); 1.96197 (contra)
2025-11-05 04:50:39,604: Loss(test): 1.51457 (total); 0.10620 (align); 1.96714 (contra)
2025-11-05 04:50:49,309: Finish train epoch 224 in 9.70 seconds.
2025-11-05 04:50:49,310: Loss(train): 1.00281 (total); 0.00581 (align); 1.94750 (contra)
2025-11-05 04:50:49,310: Loss(validation): 1.62456 (total); 0.12896 (align); 1.95956 (contra)
2025-11-05 04:50:49,310: Loss(test): 1.50298 (total); 0.10458 (align); 1.96015 (contra)
2025-11-05 04:50:58,955: Finish train epoch 225 in 9.64 seconds.
2025-11-05 04:50:58,956: Loss(train): 0.99773 (total); 0.00487 (align); 1.94672 (contra)
2025-11-05 04:50:58,956: Loss(validation): 1.65293 (total); 0.13514 (align); 1.95441 (contra)
2025-11-05 04:50:58,956: Loss(test): 1.51198 (total); 0.10641 (align); 1.95982 (contra)
2025-11-05 04:51:08,630: Finish train epoch 226 in 9.67 seconds.
2025-11-05 04:51:08,630: Loss(train): 1.00111 (total); 0.00546 (align); 1.94763 (contra)
2025-11-05 04:51:08,631: Loss(validation): 1.66395 (total); 0.13688 (align); 1.95907 (contra)
2025-11-05 04:51:08,631: Loss(test): 1.52555 (total); 0.10890 (align); 1.96210 (contra)
2025-11-05 04:51:18,218: Finish train epoch 227 in 9.59 seconds.
2025-11-05 04:51:18,218: Loss(train): 0.99823 (total); 0.00488 (align); 1.94764 (contra)
2025-11-05 04:51:18,219: Loss(validation): 1.69087 (total); 0.14244 (align); 1.95732 (contra)
2025-11-05 04:51:18,219: Loss(test): 1.57475 (total); 0.11877 (align); 1.96183 (contra)
2025-11-05 04:51:27,871: Finish train epoch 228 in 9.65 seconds.
2025-11-05 04:51:27,872: Loss(train): 0.99964 (total); 0.00493 (align); 1.95002 (contra)
2025-11-05 04:51:27,872: Loss(validation): 1.68234 (total); 0.13996 (align); 1.96508 (contra)
2025-11-05 04:51:27,873: Loss(test): 1.55853 (total); 0.11518 (align); 1.96526 (contra)
2025-11-05 04:51:37,479: Finish train epoch 229 in 9.61 seconds.
2025-11-05 04:51:37,480: Loss(train): 0.99430 (total); 0.00431 (align); 1.94554 (contra)
2025-11-05 04:51:37,480: Loss(validation): 1.65382 (total); 0.13489 (align); 1.95875 (contra)
2025-11-05 04:51:37,480: Loss(test): 1.52060 (total); 0.10820 (align); 1.95924 (contra)
2025-11-05 04:51:47,227: Finish train epoch 230 in 9.75 seconds.
2025-11-05 04:51:47,228: Loss(train): 0.98884 (total); 0.00319 (align); 1.94575 (contra)
2025-11-05 04:51:47,228: Loss(validation): 1.67045 (total); 0.13760 (align); 1.96486 (contra)
2025-11-05 04:51:47,228: Loss(test): 1.54284 (total); 0.11236 (align); 1.96206 (contra)
2025-11-05 04:51:56,898: Finish train epoch 231 in 9.67 seconds.
2025-11-05 04:51:56,899: Loss(train): 0.98686 (total); 0.00273 (align); 1.94647 (contra)
2025-11-05 04:51:56,899: Loss(validation): 1.65430 (total); 0.13496 (align); 1.95899 (contra)
2025-11-05 04:51:56,899: Loss(test): 1.48437 (total); 0.10083 (align); 1.96041 (contra)
2025-11-05 04:52:06,663: Finish train epoch 232 in 9.76 seconds.
2025-11-05 04:52:06,664: Loss(train): 0.98686 (total); 0.00262 (align); 1.94756 (contra)
2025-11-05 04:52:06,664: Loss(validation): 1.64324 (total); 0.13254 (align); 1.96106 (contra)
2025-11-05 04:52:06,665: Loss(test): 1.50365 (total); 0.10435 (align); 1.96377 (contra)
2025-11-05 04:52:16,568: Finish train epoch 233 in 9.90 seconds.
2025-11-05 04:52:16,569: Loss(train): 0.98171 (total); 0.00176 (align); 1.94577 (contra)
2025-11-05 04:52:16,570: Loss(validation): 1.62793 (total); 0.12969 (align); 1.95898 (contra)
2025-11-05 04:52:16,570: Loss(test): 1.50681 (total); 0.10508 (align); 1.96285 (contra)
2025-11-05 04:52:26,541: Finish train epoch 234 in 9.97 seconds.
2025-11-05 04:52:26,542: Loss(train): 0.98127 (total); 0.00171 (align); 1.94547 (contra)
2025-11-05 04:52:26,542: Loss(validation): 1.64636 (total); 0.13317 (align); 1.96103 (contra)
2025-11-05 04:52:26,542: Loss(test): 1.53119 (total); 0.11033 (align); 1.95904 (contra)
2025-11-05 04:52:36,294: Finish train epoch 235 in 9.75 seconds.
2025-11-05 04:52:36,295: Loss(train): 0.98174 (total); 0.00184 (align); 1.94512 (contra)
2025-11-05 04:52:36,295: Loss(validation): 1.58069 (total); 0.12041 (align); 1.95724 (contra)
2025-11-05 04:52:36,295: Loss(test): 1.49288 (total); 0.10260 (align); 1.95979 (contra)
2025-11-05 04:52:45,959: Finish train epoch 236 in 9.66 seconds.
2025-11-05 04:52:45,960: Loss(train): 0.97948 (total); 0.00135 (align); 1.94544 (contra)
2025-11-05 04:52:45,960: Loss(validation): 1.58373 (total); 0.12084 (align); 1.95911 (contra)
2025-11-05 04:52:45,961: Loss(test): 1.50325 (total); 0.10462 (align); 1.96025 (contra)
2025-11-05 04:52:55,612: Finish train epoch 237 in 9.65 seconds.
2025-11-05 04:52:55,613: Loss(train): 0.98908 (total); 0.00324 (align); 1.94576 (contra)
2025-11-05 04:52:55,613: Loss(validation): 1.73191 (total); 0.15011 (align); 1.96274 (contra)
2025-11-05 04:52:55,613: Loss(test): 1.63899 (total); 0.13140 (align); 1.96395 (contra)
2025-11-05 04:53:05,263: Finish train epoch 238 in 9.65 seconds.
2025-11-05 04:53:05,264: Loss(train): 0.99078 (total); 0.00349 (align); 1.94665 (contra)
2025-11-05 04:53:05,264: Loss(validation): 1.63529 (total); 0.13114 (align); 1.95920 (contra)
2025-11-05 04:53:05,264: Loss(test): 1.54168 (total); 0.11248 (align); 1.95857 (contra)
2025-11-05 04:53:14,947: Finish train epoch 239 in 9.68 seconds.
2025-11-05 04:53:14,948: Loss(train): 0.98917 (total); 0.00314 (align); 1.94695 (contra)
2025-11-05 04:53:14,948: Loss(validation): 1.60565 (total); 0.12500 (align); 1.96128 (contra)
2025-11-05 04:53:14,948: Loss(test): 1.50334 (total); 0.10440 (align); 1.96270 (contra)
2025-11-05 04:53:24,625: Finish train epoch 240 in 9.68 seconds.
2025-11-05 04:53:24,626: Loss(train): 0.98539 (total); 0.00253 (align); 1.94543 (contra)
2025-11-05 04:53:24,626: Loss(validation): 1.62616 (total); 0.12929 (align); 1.95941 (contra)
2025-11-05 04:53:24,627: Loss(test): 1.53372 (total); 0.11067 (align); 1.96078 (contra)
2025-11-05 04:53:34,265: Finish train epoch 241 in 9.64 seconds.
2025-11-05 04:53:34,266: Loss(train): 0.98025 (total); 0.00141 (align); 1.94638 (contra)
2025-11-05 04:53:34,266: Loss(validation): 1.61526 (total); 0.12693 (align); 1.96119 (contra)
2025-11-05 04:53:34,266: Loss(test): 1.52409 (total); 0.10874 (align); 1.96075 (contra)
2025-11-05 04:53:44,061: Finish train epoch 242 in 9.79 seconds.
2025-11-05 04:53:44,062: Loss(train): 0.97975 (total); 0.00140 (align); 1.94546 (contra)
2025-11-05 04:53:44,062: Loss(validation): 1.60551 (total); 0.12527 (align); 1.95834 (contra)
2025-11-05 04:53:44,062: Loss(test): 1.53442 (total); 0.11089 (align); 1.95991 (contra)
2025-11-05 04:53:53,643: Finish train epoch 243 in 9.58 seconds.
2025-11-05 04:53:53,644: Loss(train): 0.98250 (total); 0.00185 (align); 1.94645 (contra)
2025-11-05 04:53:53,644: Loss(validation): 1.61150 (total); 0.12658 (align); 1.95717 (contra)
2025-11-05 04:53:53,645: Loss(test): 1.54877 (total); 0.11363 (align); 1.96123 (contra)
2025-11-05 04:54:03,250: Finish train epoch 244 in 9.61 seconds.
2025-11-05 04:54:03,251: Loss(train): 0.98069 (total); 0.00158 (align); 1.94562 (contra)
2025-11-05 04:54:03,251: Loss(validation): 1.61812 (total); 0.12768 (align); 1.95943 (contra)
2025-11-05 04:54:03,251: Loss(test): 1.55610 (total); 0.11505 (align); 1.96167 (contra)
2025-11-05 04:54:12,923: Finish train epoch 245 in 9.67 seconds.
2025-11-05 04:54:12,924: Loss(train): 0.98350 (total); 0.00210 (align); 1.94599 (contra)
2025-11-05 04:54:12,925: Loss(validation): 1.64005 (total); 0.13210 (align); 1.95910 (contra)
2025-11-05 04:54:12,925: Loss(test): 1.54499 (total); 0.11290 (align); 1.96094 (contra)
2025-11-05 04:54:22,529: Finish train epoch 246 in 9.60 seconds.
2025-11-05 04:54:22,529: Loss(train): 0.97852 (total); 0.00107 (align); 1.94633 (contra)
2025-11-05 04:54:22,530: Loss(validation): 1.60636 (total); 0.12493 (align); 1.96336 (contra)
2025-11-05 04:54:22,530: Loss(test): 1.52613 (total); 0.10885 (align); 1.96378 (contra)
2025-11-05 04:54:32,124: Finish train epoch 247 in 9.59 seconds.
2025-11-05 04:54:32,125: Loss(train): 0.98262 (total); 0.00183 (align); 1.94692 (contra)
2025-11-05 04:54:32,125: Loss(validation): 1.62478 (total); 0.12867 (align); 1.96289 (contra)
2025-11-05 04:54:32,125: Loss(test): 1.56688 (total); 0.11716 (align); 1.96217 (contra)
2025-11-05 04:54:41,772: Finish train epoch 248 in 9.65 seconds.
2025-11-05 04:54:41,772: Loss(train): 0.97725 (total); 0.00089 (align); 1.94556 (contra)
2025-11-05 04:54:41,773: Loss(validation): 1.61193 (total); 0.12608 (align); 1.96310 (contra)
2025-11-05 04:54:41,773: Loss(test): 1.54909 (total); 0.11356 (align); 1.96254 (contra)
2025-11-05 04:54:51,440: Finish train epoch 249 in 9.67 seconds.
2025-11-05 04:54:51,441: Loss(train): 0.98200 (total); 0.00177 (align); 1.94631 (contra)
2025-11-05 04:54:51,441: Loss(validation): 1.63437 (total); 0.13109 (align); 1.95786 (contra)
2025-11-05 04:54:51,441: Loss(test): 1.55795 (total); 0.11526 (align); 1.96326 (contra)
2025-11-05 04:54:51,844: Saved test embeddings to /mnt/afs/250010218/multi-level-Chinese-decoding/train/duin/../../summaries/2025-11-05/4/train/ckpt/test_embeddings_epoch_250.npy
2025-11-05 04:55:01,671: Finish train epoch 250 in 9.83 seconds.
2025-11-05 04:55:01,672: Loss(train): 0.97902 (total); 0.00126 (align); 1.94544 (contra)
2025-11-05 04:55:01,672: Loss(validation): 1.61418 (total); 0.12691 (align); 1.95924 (contra)
2025-11-05 04:55:01,673: Loss(test): 1.53800 (total); 0.11170 (align); 1.95899 (contra)
2025-11-05 04:55:11,332: Finish train epoch 251 in 9.66 seconds.
2025-11-05 04:55:11,332: Loss(train): 0.97968 (total); 0.00133 (align); 1.94604 (contra)
2025-11-05 04:55:11,333: Loss(validation): 1.65401 (total); 0.13449 (align); 1.96316 (contra)
2025-11-05 04:55:11,333: Loss(test): 1.54226 (total); 0.11221 (align); 1.96245 (contra)
2025-11-05 04:55:21,026: Finish train epoch 252 in 9.69 seconds.
2025-11-05 04:55:21,027: Loss(train): 0.98253 (total); 0.00189 (align); 1.94615 (contra)
2025-11-05 04:55:21,027: Loss(validation): 1.70296 (total); 0.14466 (align); 1.95932 (contra)
2025-11-05 04:55:21,027: Loss(test): 1.54510 (total); 0.11269 (align); 1.96330 (contra)
2025-11-05 04:55:30,750: Finish train epoch 253 in 9.72 seconds.
2025-11-05 04:55:30,751: Loss(train): 0.98018 (total); 0.00151 (align); 1.94528 (contra)
2025-11-05 04:55:30,752: Loss(validation): 1.62555 (total); 0.12909 (align); 1.96018 (contra)
2025-11-05 04:55:30,752: Loss(test): 1.52776 (total); 0.10952 (align); 1.96034 (contra)
2025-11-05 04:55:40,458: Finish train epoch 254 in 9.71 seconds.
2025-11-05 04:55:40,459: Loss(train): 0.97913 (total); 0.00139 (align); 1.94434 (contra)
2025-11-05 04:55:40,460: Loss(validation): 1.63281 (total); 0.13053 (align); 1.96035 (contra)
2025-11-05 04:55:40,460: Loss(test): 1.53130 (total); 0.11019 (align); 1.96070 (contra)
2025-11-05 04:55:50,101: Finish train epoch 255 in 9.64 seconds.
2025-11-05 04:55:50,102: Loss(train): 0.97981 (total); 0.00132 (align); 1.94641 (contra)
2025-11-05 04:55:50,102: Loss(validation): 1.63507 (total); 0.13102 (align); 1.95990 (contra)
2025-11-05 04:55:50,102: Loss(test): 1.53160 (total); 0.11029 (align); 1.96030 (contra)
2025-11-05 04:55:59,687: Finish train epoch 256 in 9.58 seconds.
2025-11-05 04:55:59,687: Loss(train): 0.98092 (total); 0.00163 (align); 1.94551 (contra)
2025-11-05 04:55:59,688: Loss(validation): 1.61525 (total); 0.12695 (align); 1.96101 (contra)
2025-11-05 04:55:59,688: Loss(test): 1.52782 (total); 0.10916 (align); 1.96400 (contra)
2025-11-05 04:56:09,310: Finish train epoch 257 in 9.62 seconds.
2025-11-05 04:56:09,311: Loss(train): 0.98409 (total); 0.00227 (align); 1.94545 (contra)
2025-11-05 04:56:09,311: Loss(validation): 1.62160 (total); 0.12852 (align); 1.95801 (contra)
2025-11-05 04:56:09,311: Loss(test): 1.50562 (total); 0.10527 (align); 1.95854 (contra)
2025-11-05 04:56:18,979: Finish train epoch 258 in 9.67 seconds.
2025-11-05 04:56:18,980: Loss(train): 0.98261 (total); 0.00193 (align); 1.94596 (contra)
2025-11-05 04:56:18,980: Loss(validation): 1.63521 (total); 0.13119 (align); 1.95853 (contra)
2025-11-05 04:56:18,981: Loss(test): 1.49419 (total); 0.10295 (align); 1.95893 (contra)
2025-11-05 04:56:28,724: Finish train epoch 259 in 9.74 seconds.
2025-11-05 04:56:28,725: Loss(train): 0.97994 (total); 0.00153 (align); 1.94456 (contra)
2025-11-05 04:56:28,725: Loss(validation): 1.64213 (total); 0.13265 (align); 1.95780 (contra)
2025-11-05 04:56:28,725: Loss(test): 1.52078 (total); 0.10834 (align); 1.95820 (contra)
2025-11-05 04:56:38,309: Finish train epoch 260 in 9.58 seconds.
2025-11-05 04:56:38,310: Loss(train): 0.98108 (total); 0.00172 (align); 1.94496 (contra)
2025-11-05 04:56:38,310: Loss(validation): 1.64636 (total); 0.13350 (align); 1.95776 (contra)
2025-11-05 04:56:38,310: Loss(test): 1.51659 (total); 0.10709 (align); 1.96228 (contra)
2025-11-05 04:56:48,158: Finish train epoch 261 in 9.85 seconds.
2025-11-05 04:56:48,159: Loss(train): 0.98226 (total); 0.00191 (align); 1.94546 (contra)
2025-11-05 04:56:48,159: Loss(validation): 1.61297 (total); 0.12690 (align); 1.95697 (contra)
2025-11-05 04:56:48,159: Loss(test): 1.49151 (total); 0.10184 (align); 1.96465 (contra)
2025-11-05 04:56:57,840: Finish train epoch 262 in 9.68 seconds.
2025-11-05 04:56:57,841: Loss(train): 0.97755 (total); 0.00093 (align); 1.94577 (contra)
2025-11-05 04:56:57,842: Loss(validation): 1.60723 (total); 0.12576 (align); 1.95681 (contra)
2025-11-05 04:56:57,842: Loss(test): 1.53596 (total); 0.11126 (align); 1.95935 (contra)
2025-11-05 04:57:07,515: Finish train epoch 263 in 9.67 seconds.
2025-11-05 04:57:07,516: Loss(train): 0.97812 (total); 0.00105 (align); 1.94575 (contra)
2025-11-05 04:57:07,516: Loss(validation): 1.59652 (total); 0.12329 (align); 1.96016 (contra)
2025-11-05 04:57:07,517: Loss(test): 1.50461 (total); 0.10475 (align); 1.96170 (contra)
2025-11-05 04:57:17,190: Finish train epoch 264 in 9.67 seconds.
2025-11-05 04:57:17,191: Loss(train): 0.97884 (total); 0.00131 (align); 1.94455 (contra)
2025-11-05 04:57:17,191: Loss(validation): 1.60767 (total); 0.12585 (align); 1.95681 (contra)
2025-11-05 04:57:17,191: Loss(test): 1.50218 (total); 0.10457 (align); 1.95863 (contra)
2025-11-05 04:57:26,850: Finish train epoch 265 in 9.66 seconds.
2025-11-05 04:57:26,851: Loss(train): 0.98305 (total); 0.00209 (align); 1.94515 (contra)
2025-11-05 04:57:26,851: Loss(validation): 1.60137 (total); 0.12449 (align); 1.95779 (contra)
2025-11-05 04:57:26,851: Loss(test): 1.51761 (total); 0.10757 (align); 1.95954 (contra)
2025-11-05 04:57:36,514: Finish train epoch 266 in 9.66 seconds.
2025-11-05 04:57:36,515: Loss(train): 0.97904 (total); 0.00130 (align); 1.94506 (contra)
2025-11-05 04:57:36,515: Loss(validation): 1.59047 (total); 0.12244 (align); 1.95653 (contra)
2025-11-05 04:57:36,515: Loss(test): 1.51284 (total); 0.10629 (align); 1.96274 (contra)
2025-11-05 04:57:46,156: Finish train epoch 267 in 9.64 seconds.
2025-11-05 04:57:46,157: Loss(train): 0.97631 (total); 0.00082 (align); 1.94441 (contra)
2025-11-05 04:57:46,157: Loss(validation): 1.58509 (total); 0.12118 (align); 1.95836 (contra)
2025-11-05 04:57:46,157: Loss(test): 1.49321 (total); 0.10241 (align); 1.96234 (contra)
2025-11-05 04:57:55,753: Finish train epoch 268 in 9.60 seconds.
2025-11-05 04:57:55,754: Loss(train): 0.97836 (total); 0.00129 (align); 1.94382 (contra)
2025-11-05 04:57:55,754: Loss(validation): 1.56079 (total); 0.11641 (align); 1.95744 (contra)
2025-11-05 04:57:55,754: Loss(test): 1.46700 (total); 0.09716 (align); 1.96238 (contra)
2025-11-05 04:58:05,426: Finish train epoch 269 in 9.67 seconds.
2025-11-05 04:58:05,427: Loss(train): 0.98049 (total); 0.00149 (align); 1.94604 (contra)
2025-11-05 04:58:05,427: Loss(validation): 1.56729 (total); 0.11792 (align); 1.95533 (contra)
2025-11-05 04:58:05,427: Loss(test): 1.48521 (total); 0.10109 (align); 1.95954 (contra)
2025-11-05 04:58:15,123: Finish train epoch 270 in 9.69 seconds.
2025-11-05 04:58:15,123: Loss(train): 0.97774 (total); 0.00102 (align); 1.94531 (contra)
2025-11-05 04:58:15,124: Loss(validation): 1.59060 (total); 0.12226 (align); 1.95863 (contra)
2025-11-05 04:58:15,124: Loss(test): 1.48149 (total); 0.10002 (align); 1.96283 (contra)
2025-11-05 04:58:24,839: Finish train epoch 271 in 9.72 seconds.
2025-11-05 04:58:24,840: Loss(train): 0.98289 (total); 0.00216 (align); 1.94420 (contra)
2025-11-05 04:58:24,840: Loss(validation): 1.59336 (total); 0.12302 (align); 1.95654 (contra)
2025-11-05 04:58:24,840: Loss(test): 1.48635 (total); 0.10106 (align); 1.96210 (contra)
2025-11-05 04:58:34,502: Finish train epoch 272 in 9.66 seconds.
2025-11-05 04:58:34,503: Loss(train): 0.97596 (total); 0.00072 (align); 1.94471 (contra)
2025-11-05 04:58:34,503: Loss(validation): 1.59292 (total); 0.12278 (align); 1.95806 (contra)
2025-11-05 04:58:34,504: Loss(test): 1.50119 (total); 0.10403 (align); 1.96210 (contra)
2025-11-05 04:58:44,137: Finish train epoch 273 in 9.63 seconds.
2025-11-05 04:58:44,138: Loss(train): 0.98141 (total); 0.00178 (align); 1.94506 (contra)
2025-11-05 04:58:44,138: Loss(validation): 1.59471 (total); 0.12328 (align); 1.95661 (contra)
2025-11-05 04:58:44,138: Loss(test): 1.48147 (total); 0.10022 (align); 1.96071 (contra)
2025-11-05 04:58:53,805: Finish train epoch 274 in 9.67 seconds.
2025-11-05 04:58:53,806: Loss(train): 0.97975 (total); 0.00142 (align); 1.94525 (contra)
2025-11-05 04:58:53,806: Loss(validation): 1.59115 (total); 0.12232 (align); 1.95909 (contra)
2025-11-05 04:58:53,807: Loss(test): 1.47233 (total); 0.09845 (align); 1.96019 (contra)
2025-11-05 04:59:03,502: Finish train epoch 275 in 9.70 seconds.
2025-11-05 04:59:03,503: Loss(train): 0.98110 (total); 0.00164 (align); 1.94580 (contra)
2025-11-05 04:59:03,503: Loss(validation): 1.59694 (total); 0.12358 (align); 1.95807 (contra)
2025-11-05 04:59:03,504: Loss(test): 1.47329 (total); 0.09888 (align); 1.95782 (contra)
2025-11-05 04:59:13,154: Finish train epoch 276 in 9.65 seconds.
2025-11-05 04:59:13,155: Loss(train): 0.97551 (total); 0.00060 (align); 1.94506 (contra)
2025-11-05 04:59:13,155: Loss(validation): 1.60389 (total); 0.12486 (align); 1.95921 (contra)
2025-11-05 04:59:13,155: Loss(test): 1.49060 (total); 0.10173 (align); 1.96385 (contra)
2025-11-05 04:59:22,819: Finish train epoch 277 in 9.66 seconds.
2025-11-05 04:59:22,819: Loss(train): 0.97579 (total); 0.00061 (align); 1.94547 (contra)
2025-11-05 04:59:22,820: Loss(validation): 1.60187 (total); 0.12426 (align); 1.96117 (contra)
2025-11-05 04:59:22,820: Loss(test): 1.48376 (total); 0.10048 (align); 1.96271 (contra)
2025-11-05 04:59:32,456: Finish train epoch 278 in 9.64 seconds.
2025-11-05 04:59:32,457: Loss(train): 0.98259 (total); 0.00195 (align); 1.94567 (contra)
2025-11-05 04:59:32,457: Loss(validation): 1.57024 (total); 0.11823 (align); 1.95822 (contra)
2025-11-05 04:59:32,458: Loss(test): 1.48685 (total); 0.10121 (align); 1.96162 (contra)
2025-11-05 04:59:42,058: Finish train epoch 279 in 9.60 seconds.
2025-11-05 04:59:42,059: Loss(train): 0.97815 (total); 0.00106 (align); 1.94568 (contra)
2025-11-05 04:59:42,059: Loss(validation): 1.58388 (total); 0.12114 (align); 1.95632 (contra)
2025-11-05 04:59:42,059: Loss(test): 1.49620 (total); 0.10317 (align); 1.96069 (contra)
2025-11-05 04:59:51,793: Finish train epoch 280 in 9.73 seconds.
2025-11-05 04:59:51,794: Loss(train): 0.97738 (total); 0.00098 (align); 1.94492 (contra)
2025-11-05 04:59:51,794: Loss(validation): 1.56970 (total); 0.11815 (align); 1.95790 (contra)
2025-11-05 04:59:51,795: Loss(test): 1.48299 (total); 0.10037 (align); 1.96230 (contra)
2025-11-05 05:00:01,550: Finish train epoch 281 in 9.75 seconds.
2025-11-05 05:00:01,551: Loss(train): 0.97736 (total); 0.00096 (align); 1.94509 (contra)
2025-11-05 05:00:01,551: Loss(validation): 1.59051 (total); 0.12219 (align); 1.95913 (contra)
2025-11-05 05:00:01,551: Loss(test): 1.50620 (total); 0.10501 (align); 1.96229 (contra)
2025-11-05 05:00:11,347: Finish train epoch 282 in 9.80 seconds.
2025-11-05 05:00:11,348: Loss(train): 0.97592 (total); 0.00071 (align); 1.94471 (contra)
2025-11-05 05:00:11,348: Loss(validation): 1.58145 (total); 0.12007 (align); 1.96221 (contra)
2025-11-05 05:00:11,348: Loss(test): 1.49576 (total); 0.10291 (align); 1.96243 (contra)
2025-11-05 05:00:21,484: Finish train epoch 283 in 10.14 seconds.
2025-11-05 05:00:21,485: Loss(train): 0.97637 (total); 0.00083 (align); 1.94440 (contra)
2025-11-05 05:00:21,485: Loss(validation): 1.58351 (total); 0.12095 (align); 1.95748 (contra)
2025-11-05 05:00:21,485: Loss(test): 1.51671 (total); 0.10729 (align); 1.96053 (contra)
2025-11-05 05:00:32,304: Finish train epoch 284 in 10.82 seconds.
2025-11-05 05:00:32,305: Loss(train): 0.98159 (total); 0.00181 (align); 1.94503 (contra)
2025-11-05 05:00:32,305: Loss(validation): 1.57696 (total); 0.11958 (align); 1.95814 (contra)
2025-11-05 05:00:32,306: Loss(test): 1.51765 (total); 0.10763 (align); 1.95894 (contra)
2025-11-05 05:00:42,901: Finish train epoch 285 in 10.59 seconds.
2025-11-05 05:00:42,901: Loss(train): 0.97960 (total); 0.00141 (align); 1.94506 (contra)
2025-11-05 05:00:42,902: Loss(validation): 1.57919 (total); 0.12014 (align); 1.95695 (contra)
2025-11-05 05:00:42,902: Loss(test): 1.51244 (total); 0.10625 (align); 1.96242 (contra)
2025-11-05 05:00:52,783: Finish train epoch 286 in 9.88 seconds.
2025-11-05 05:00:52,784: Loss(train): 0.97648 (total); 0.00072 (align); 1.94577 (contra)
2025-11-05 05:00:52,784: Loss(validation): 1.57315 (total); 0.11871 (align); 1.95923 (contra)
2025-11-05 05:00:52,784: Loss(test): 1.50798 (total); 0.10544 (align); 1.96157 (contra)
2025-11-05 05:01:02,706: Finish train epoch 287 in 9.92 seconds.
2025-11-05 05:01:02,707: Loss(train): 0.97812 (total); 0.00120 (align); 1.94425 (contra)
2025-11-05 05:01:02,707: Loss(validation): 1.56516 (total); 0.11715 (align); 1.95884 (contra)
2025-11-05 05:01:02,707: Loss(test): 1.50230 (total); 0.10449 (align); 1.95967 (contra)
2025-11-05 05:01:12,474: Finish train epoch 288 in 9.77 seconds.
2025-11-05 05:01:12,475: Loss(train): 0.98077 (total); 0.00165 (align); 1.94505 (contra)
2025-11-05 05:01:12,475: Loss(validation): 1.57160 (total); 0.11873 (align); 1.95594 (contra)
2025-11-05 05:01:12,475: Loss(test): 1.50979 (total); 0.10594 (align); 1.96021 (contra)
2025-11-05 05:01:22,218: Finish train epoch 289 in 9.74 seconds.
2025-11-05 05:01:22,219: Loss(train): 0.97739 (total); 0.00101 (align); 1.94469 (contra)
2025-11-05 05:01:22,219: Loss(validation): 1.57063 (total); 0.11812 (align); 1.96001 (contra)
2025-11-05 05:01:22,219: Loss(test): 1.50563 (total); 0.10489 (align); 1.96236 (contra)
2025-11-05 05:01:32,129: Finish train epoch 290 in 9.91 seconds.
2025-11-05 05:01:32,130: Loss(train): 0.97690 (total); 0.00091 (align); 1.94469 (contra)
2025-11-05 05:01:32,130: Loss(validation): 1.56392 (total); 0.11682 (align); 1.95965 (contra)
2025-11-05 05:01:32,130: Loss(test): 1.50429 (total); 0.10462 (align); 1.96237 (contra)
2025-11-05 05:01:41,847: Finish train epoch 291 in 9.72 seconds.
2025-11-05 05:01:41,848: Loss(train): 0.97802 (total); 0.00113 (align); 1.94473 (contra)
2025-11-05 05:01:41,848: Loss(validation): 1.55944 (total); 0.11596 (align); 1.95928 (contra)
2025-11-05 05:01:41,849: Loss(test): 1.50735 (total); 0.10522 (align); 1.96252 (contra)
2025-11-05 05:01:51,841: Finish train epoch 292 in 9.99 seconds.
2025-11-05 05:01:51,842: Loss(train): 0.97556 (total); 0.00067 (align); 1.94438 (contra)
2025-11-05 05:01:51,842: Loss(validation): 1.55860 (total); 0.11595 (align); 1.95775 (contra)
2025-11-05 05:01:51,843: Loss(test): 1.50895 (total); 0.10521 (align); 1.96579 (contra)
2025-11-05 05:02:01,922: Finish train epoch 293 in 10.08 seconds.
2025-11-05 05:02:01,923: Loss(train): 0.97521 (total); 0.00055 (align); 1.94494 (contra)
2025-11-05 05:02:01,923: Loss(validation): 1.55606 (total); 0.11535 (align); 1.95861 (contra)
2025-11-05 05:02:01,923: Loss(test): 1.51041 (total); 0.10587 (align); 1.96208 (contra)
2025-11-05 05:02:11,647: Finish train epoch 294 in 9.72 seconds.
2025-11-05 05:02:11,648: Loss(train): 0.97567 (total); 0.00065 (align); 1.94482 (contra)
2025-11-05 05:02:11,648: Loss(validation): 1.55687 (total); 0.11544 (align); 1.95930 (contra)
2025-11-05 05:02:11,648: Loss(test): 1.51164 (total); 0.10621 (align); 1.96117 (contra)
2025-11-05 05:02:21,305: Finish train epoch 295 in 9.66 seconds.
2025-11-05 05:02:21,306: Loss(train): 0.97788 (total); 0.00119 (align); 1.94390 (contra)
2025-11-05 05:02:21,306: Loss(validation): 1.56022 (total); 0.11643 (align); 1.95614 (contra)
2025-11-05 05:02:21,306: Loss(test): 1.49878 (total); 0.10366 (align); 1.96095 (contra)
2025-11-05 05:02:31,097: Finish train epoch 296 in 9.79 seconds.
2025-11-05 05:02:31,098: Loss(train): 0.98029 (total); 0.00154 (align); 1.94515 (contra)
2025-11-05 05:02:31,098: Loss(validation): 1.55694 (total); 0.11569 (align); 1.95700 (contra)
2025-11-05 05:02:31,098: Loss(test): 1.50595 (total); 0.10537 (align); 1.95817 (contra)
2025-11-05 05:02:40,833: Finish train epoch 297 in 9.73 seconds.
2025-11-05 05:02:40,834: Loss(train): 0.97707 (total); 0.00098 (align); 1.94430 (contra)
2025-11-05 05:02:40,834: Loss(validation): 1.56282 (total); 0.11651 (align); 1.96057 (contra)
2025-11-05 05:02:40,834: Loss(test): 1.50352 (total); 0.10490 (align); 1.95808 (contra)
2025-11-05 05:02:50,413: Finish train epoch 298 in 9.58 seconds.
2025-11-05 05:02:50,414: Loss(train): 0.97723 (total); 0.00107 (align); 1.94374 (contra)
2025-11-05 05:02:50,414: Loss(validation): 1.55736 (total); 0.11550 (align); 1.95976 (contra)
2025-11-05 05:02:50,414: Loss(test): 1.50497 (total); 0.10516 (align); 1.95830 (contra)
2025-11-05 05:02:59,991: Finish train epoch 299 in 9.58 seconds.
2025-11-05 05:02:59,991: Loss(train): 0.97839 (total); 0.00125 (align); 1.94428 (contra)
2025-11-05 05:02:59,992: Loss(validation): 1.55604 (total); 0.11527 (align); 1.95933 (contra)
2025-11-05 05:02:59,992: Loss(test): 1.50286 (total); 0.10403 (align); 1.96545 (contra)
2025-11-05 05:03:00,395: Saved test embeddings to /mnt/afs/250010218/multi-level-Chinese-decoding/train/duin/../../summaries/2025-11-05/4/train/ckpt/test_embeddings_epoch_300.npy
2025-11-05 05:03:00,402: INFO: The top-10 channels are ['SM9', 'SM7', 'SM8', 'SM6', 'SM10', 'SM11', 'P3', 'P4', 'SM5', 'CI9'] with weights [0.05256605, 0.05076634, 0.050652087, 0.049921967, 0.043313563, 0.034363028, 0.03015171, 0.029827388, 0.02044, 0.019526672], with channel weight distribution:

0.01953 - 0.02283    | ####################
0.02283 - 0.02613    | 
0.02613 - 0.02944    | 
0.02944 - 0.03274    | ####################
0.03274 - 0.03605    | ##########
0.03605 - 0.03935    | 
0.03935 - 0.04265    | 
0.04265 - 0.04596    | ##########
0.04596 - 0.04926    | 
0.04926 - 0.05257    | ########################################

2025-11-05 05:03:00,403: Finish the (Visual Embedding Alignment) training process of experiment train-task-all-speak-test-task-all-speak.
2025-11-05 05:03:00,403: Best model occurred at epoch 168 with minimum validation loss 1.529824.
2025-11-05 05:03:00,403: Training finished with dataset seeg_he2023xuanwu.
