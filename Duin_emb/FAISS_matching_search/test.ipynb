{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from faiss_search import faiss_topk_labels,compute_topk_accuracy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['丝瓜', '你', '关门', '凳子', '厕所', '口渴', '吃',\\\n",
    "               '喝', '嘴巴', '外卖', '头疼', '家人', '小刀', '帮助',\\\n",
    "                  '平静', '心情', '怎样', '感觉', '愿意', '我', '手机',\\\n",
    "                    '找', '把', '护士', '拿', '换药', '放在', '是', '有',\\\n",
    "                          '朋友', '橙汁', '毛巾', '汤圆', '漂亮', '热水', \\\n",
    "                            '猪肉', '玩', '电脑', '看', '碗', '穿', '篮球',\\\n",
    "                                  '米饭', '给', '脸盆', '菠萝', '葱花', '蒜泥',\\\n",
    "                                      '衣服', '豆腐', '软糖', '醋', '钢琴', '问题',\\\n",
    "                                          '需要', '青菜', '面条', '音乐', '预约', '香肠', '鱼块']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npz_vis(path=\"Duin_vit_embeddings.npz\"):\n",
    "    data = np.load(path, allow_pickle=True)\n",
    "    return data[\"chars\"], data[\"embeddings\"], dict(data[\"meta\"])\n",
    "\n",
    "def load_npz_semantic(path):\n",
    "    data = np.load(path, allow_pickle=True)\n",
    "    words = data['words']\n",
    "    emb_cls = data['emb_cls']\n",
    "    emb_mean = data['emb_mean']\n",
    "    emb_max = data['emb_max']\n",
    "    emb_weighted = data['emb_weighted']\n",
    "    emb_mixed = data['emb_mixed']\n",
    "    return words, emb_cls, emb_mean, emb_max, emb_weighted, emb_mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_embeddings(path):\n",
    "    data = np.load(path, allow_pickle=True)\n",
    "    labels = data[:,-1]\n",
    "    #把label的元素转化为int\n",
    "    labels = labels.astype(int)\n",
    "    labels=[label_list[i] for i in labels]\n",
    "    labels = np.array(labels)\n",
    "    embeddings = data[:,0:-1]\n",
    "    return labels, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "语义数据格式\n",
      "GT_labels_semantic: (61,)\n",
      "GT_embeddings_semantic: (61, 768)\n",
      "GT_embeddings_semantic Average: -0.00010871876\n",
      "test_labels_semantic: (329,)\n",
      "test_embeddings_semantic: (329, 768)\n",
      "test_embeddings_semantic Average: -5.5004056519686606e-05\n"
     ]
    }
   ],
   "source": [
    "# 读取GT语义embeddings和模型输出的语义embeddigs\n",
    "words, emb_cls, emb_mean, emb_max, emb_weighted, emb_mixed = \\\n",
    "    load_npz_semantic('../GT_embeddings/61words/Duin_bert_embeddings.npz')\n",
    "\n",
    "GT_labels_semantic = words\n",
    "GT_embeddings_semantic = emb_mean\n",
    "test_labels_semantic, test_embeddings_semantic = load_test_embeddings('../output_embeddings/Semantic_Doublelayer_(512-256)_lr1e-4/test_embeddings_epoch_200_2')\n",
    "print('语义数据格式')\n",
    "print('GT_labels_semantic:', GT_labels_semantic.shape)\n",
    "print('GT_embeddings_semantic:', GT_embeddings_semantic.shape)\n",
    "print('GT_embeddings_semantic Average:', np.mean(GT_embeddings_semantic))\n",
    "print('test_labels_semantic:', test_labels_semantic.shape)\n",
    "print('test_embeddings_semantic:', test_embeddings_semantic.shape)\n",
    "print('test_embeddings_semantic Average:', np.mean(test_embeddings_semantic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "归一化后\n",
      "GT_embeddings_semantic Average: -0.00010871877\n",
      "test_embeddings_semantic Average: -5.50040562025555e-05\n"
     ]
    }
   ],
   "source": [
    "# 归一化\n",
    "GT_embeddings_semantic = GT_embeddings_semantic / np.linalg.norm(GT_embeddings_semantic, axis=1, keepdims=True)\n",
    "test_embeddings_semantic = test_embeddings_semantic / np.linalg.norm(test_embeddings_semantic, axis=1, keepdims=True)\n",
    "print('归一化后')\n",
    "print('GT_embeddings_semantic Average:', np.mean(GT_embeddings_semantic))\n",
    "print('test_embeddings_semantic Average:', np.mean(test_embeddings_semantic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "topk_labels, topk_probs = faiss_topk_labels(\n",
    "    GT_embeddings_semantic,   # (61, 768)\n",
    "    GT_labels_semantic,       # 长度61\n",
    "    test_embeddings_semantic, # (329, 768)\n",
    "    topk=10,\n",
    "    use_gpu=False,\n",
    "    normalize=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 1\n",
    "print(topk_labels[sample])   # 样本0的前10个预测标签\n",
    "print(topk_probs[sample])    # 对应的softmax概率\n",
    "print(test_labels_semantic[sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_topk_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m accs \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_topk_accuracy\u001b[49m(topk_labels, test_labels_semantic, ks\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(accs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'compute_topk_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "accs = compute_topk_accuracy(topk_labels, test_labels_semantic, ks=(1,3,5,10))\n",
    "print(accs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graduation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
